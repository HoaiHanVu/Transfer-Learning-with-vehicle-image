{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'training_set'\n",
    "validation_data_dir = 'test_set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.MobileNet with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = applications.MobileNet(weights = 'imagenet',\n",
    "                                include_top = False,\n",
    "                                input_shape = (img_width, \n",
    "                                               img_height, 3))\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobile.layers[:5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mobile.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_model = Model(inputs = mobile.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_model.compile(loss = 'binary_crossentropy',\n",
    "                     optimizer = 'adam',\n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   rotation_range = 0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9110 images belonging to 2 classes.\n",
      "Found 2993 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (img_height, \n",
    "                                                                   img_width),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size = (img_height,\n",
    "                                                                       img_width),\n",
    "                                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('bike_car_mobilenet.h5',\n",
    "                             monitor = 'val_loss',\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 1)\n",
    "\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0.001,\n",
    "                      mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/285 [..............................] - ETA: 25:21 - loss: 0.9272 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  2/285 [..............................] - ETA: 13:04 - loss: 0.4640 - accuracy: 0.7344WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  3/285 [..............................] - ETA: 12:29 - loss: 0.3474 - accuracy: 0.8021WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  4/285 [..............................] - ETA: 12:21 - loss: 0.3870 - accuracy: 0.8438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  5/285 [..............................] - ETA: 12:29 - loss: 1.3160 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  6/285 [..............................] - ETA: 12:25 - loss: 1.8146 - accuracy: 0.8698WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  7/285 [..............................] - ETA: 12:00 - loss: 2.8563 - accuracy: 0.8661WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  8/285 [..............................] - ETA: 11:44 - loss: 4.2969 - accuracy: 0.8555WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  9/285 [..............................] - ETA: 11:29 - loss: 6.3508 - accuracy: 0.8576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 10/285 [>.............................] - ETA: 11:19 - loss: 5.7942 - accuracy: 0.8687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 11/285 [>.............................] - ETA: 11:11 - loss: 5.2674 - accuracy: 0.8807WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 12/285 [>.............................] - ETA: 11:06 - loss: 5.0109 - accuracy: 0.8854WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 13/285 [>.............................] - ETA: 11:07 - loss: 5.3518 - accuracy: 0.8870WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 14/285 [>.............................] - ETA: 10:58 - loss: 7.9968 - accuracy: 0.8795WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 15/285 [>.............................] - ETA: 10:51 - loss: 7.9690 - accuracy: 0.8854WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 16/285 [>.............................] - ETA: 10:44 - loss: 7.4709 - accuracy: 0.8926WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 17/285 [>.............................] - ETA: 10:39 - loss: 7.0461 - accuracy: 0.8971WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 18/285 [>.............................] - ETA: 10:33 - loss: 6.6547 - accuracy: 0.9028WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 19/285 [=>............................] - ETA: 10:26 - loss: 6.9466 - accuracy: 0.9013WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 20/285 [=>............................] - ETA: 10:23 - loss: 6.9030 - accuracy: 0.9016WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 21/285 [=>............................] - ETA: 10:19 - loss: 6.6011 - accuracy: 0.9048WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 22/285 [=>............................] - ETA: 10:15 - loss: 6.3010 - accuracy: 0.9091WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 23/285 [=>............................] - ETA: 10:10 - loss: 6.1948 - accuracy: 0.9049WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 24/285 [=>............................] - ETA: 10:07 - loss: 5.9367 - accuracy: 0.9089WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 25/285 [=>............................] - ETA: 10:06 - loss: 5.7082 - accuracy: 0.9112WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 26/285 [=>............................] - ETA: 10:05 - loss: 5.4887 - accuracy: 0.9147WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 27/285 [=>............................] - ETA: 10:04 - loss: 5.2854 - accuracy: 0.9178WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 28/285 [=>............................] - ETA: 10:02 - loss: 5.0966 - accuracy: 0.9208WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 29/285 [==>...........................] - ETA: 10:00 - loss: 4.9503 - accuracy: 0.9224WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 30/285 [==>...........................] - ETA: 9:58 - loss: 4.7853 - accuracy: 0.9250 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 31/285 [==>...........................] - ETA: 9:57 - loss: 4.6512 - accuracy: 0.9264WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 32/285 [==>...........................] - ETA: 9:56 - loss: 4.5058 - accuracy: 0.9287WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 33/285 [==>...........................] - ETA: 9:54 - loss: 4.4482 - accuracy: 0.9299WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 34/285 [==>...........................] - ETA: 9:51 - loss: 4.3747 - accuracy: 0.9292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 35/285 [==>...........................] - ETA: 9:49 - loss: 4.5696 - accuracy: 0.9250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 36/285 [==>...........................] - ETA: 9:46 - loss: 4.4426 - accuracy: 0.9271WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 37/285 [==>...........................] - ETA: 9:44 - loss: 4.3226 - accuracy: 0.9291WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 38/285 [===>..........................] - ETA: 9:42 - loss: 4.2088 - accuracy: 0.9309WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 39/285 [===>..........................] - ETA: 9:39 - loss: 4.2108 - accuracy: 0.9239WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 40/285 [===>..........................] - ETA: 9:37 - loss: 4.1056 - accuracy: 0.9258WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 41/285 [===>..........................] - ETA: 9:35 - loss: 4.0122 - accuracy: 0.9268WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 42/285 [===>..........................] - ETA: 9:33 - loss: 3.9169 - accuracy: 0.9286WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 43/285 [===>..........................] - ETA: 9:30 - loss: 3.8294 - accuracy: 0.9295WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 44/285 [===>..........................] - ETA: 9:28 - loss: 3.7519 - accuracy: 0.9304WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 45/285 [===>..........................] - ETA: 9:26 - loss: 3.6685 - accuracy: 0.9319WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 46/285 [===>..........................] - ETA: 9:24 - loss: 3.5887 - accuracy: 0.9334WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 47/285 [===>..........................] - ETA: 9:21 - loss: 3.5308 - accuracy: 0.9342WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 48/285 [====>.........................] - ETA: 9:19 - loss: 3.4573 - accuracy: 0.9355WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 49/285 [====>.........................] - ETA: 9:16 - loss: 3.3867 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 50/285 [====>.........................] - ETA: 9:14 - loss: 3.3190 - accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 51/285 [====>.........................] - ETA: 9:12 - loss: 3.2539 - accuracy: 0.9393WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 52/285 [====>.........................] - ETA: 9:10 - loss: 3.2387 - accuracy: 0.9399WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 53/285 [====>.........................] - ETA: 9:07 - loss: 3.1776 - accuracy: 0.9410WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 54/285 [====>.........................] - ETA: 9:05 - loss: 3.1188 - accuracy: 0.9421WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 55/285 [====>.........................] - ETA: 9:02 - loss: 3.0706 - accuracy: 0.9426WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 56/285 [====>.........................] - ETA: 9:00 - loss: 3.0158 - accuracy: 0.9436WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 57/285 [=====>........................] - ETA: 8:58 - loss: 2.9729 - accuracy: 0.9441WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 58/285 [=====>........................] - ETA: 8:56 - loss: 2.9317 - accuracy: 0.9445WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 59/285 [=====>........................] - ETA: 8:54 - loss: 2.8948 - accuracy: 0.9439WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 60/285 [=====>........................] - ETA: 8:52 - loss: 2.8466 - accuracy: 0.9448WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 61/285 [=====>........................] - ETA: 8:50 - loss: 2.8007 - accuracy: 0.9452WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 62/285 [=====>........................] - ETA: 8:47 - loss: 2.7556 - accuracy: 0.9461WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 63/285 [=====>........................] - ETA: 8:45 - loss: 2.7118 - accuracy: 0.9469WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 64/285 [=====>........................] - ETA: 8:42 - loss: 2.6695 - accuracy: 0.9478WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 65/285 [=====>........................] - ETA: 8:40 - loss: 2.6287 - accuracy: 0.9486WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 66/285 [=====>........................] - ETA: 8:37 - loss: 2.5889 - accuracy: 0.9493WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 67/285 [======>.......................] - ETA: 8:34 - loss: 2.5502 - accuracy: 0.9501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 68/285 [======>.......................] - ETA: 8:32 - loss: 2.5305 - accuracy: 0.9494WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 69/285 [======>.......................] - ETA: 8:29 - loss: 2.4939 - accuracy: 0.9502WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 70/285 [======>.......................] - ETA: 8:26 - loss: 2.4582 - accuracy: 0.9509WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 71/285 [======>.......................] - ETA: 8:24 - loss: 2.4236 - accuracy: 0.9516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 72/285 [======>.......................] - ETA: 8:22 - loss: 2.3899 - accuracy: 0.9523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 73/285 [======>.......................] - ETA: 8:19 - loss: 2.3572 - accuracy: 0.9529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 74/285 [======>.......................] - ETA: 8:16 - loss: 2.3368 - accuracy: 0.9523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 75/285 [======>.......................] - ETA: 8:14 - loss: 2.3058 - accuracy: 0.9529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 76/285 [=======>......................] - ETA: 8:11 - loss: 2.2808 - accuracy: 0.9531WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 77/285 [=======>......................] - ETA: 8:09 - loss: 2.2528 - accuracy: 0.9533WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 78/285 [=======>......................] - ETA: 8:06 - loss: 2.2239 - accuracy: 0.9539WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 79/285 [=======>......................] - ETA: 8:04 - loss: 2.1957 - accuracy: 0.9545WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 80/285 [=======>......................] - ETA: 8:01 - loss: 2.1694 - accuracy: 0.9547WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 81/285 [=======>......................] - ETA: 7:58 - loss: 2.1426 - accuracy: 0.9552WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 82/285 [=======>......................] - ETA: 7:56 - loss: 2.1171 - accuracy: 0.9554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 83/285 [=======>......................] - ETA: 7:54 - loss: 2.0916 - accuracy: 0.9559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 84/285 [=======>......................] - ETA: 7:51 - loss: 2.0667 - accuracy: 0.9565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 85/285 [=======>......................] - ETA: 7:49 - loss: 2.1227 - accuracy: 0.9559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 86/285 [========>.....................] - ETA: 7:46 - loss: 2.0980 - accuracy: 0.9564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 87/285 [========>.....................] - ETA: 7:44 - loss: 2.0761 - accuracy: 0.9565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 88/285 [========>.....................] - ETA: 7:41 - loss: 2.0750 - accuracy: 0.9563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 89/285 [========>.....................] - ETA: 7:39 - loss: 2.0523 - accuracy: 0.9565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 90/285 [========>.....................] - ETA: 7:36 - loss: 2.0295 - accuracy: 0.9569WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 91/285 [========>.....................] - ETA: 7:34 - loss: 2.0090 - accuracy: 0.9571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 92/285 [========>.....................] - ETA: 7:31 - loss: 1.9887 - accuracy: 0.9572WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 93/285 [========>.....................] - ETA: 7:29 - loss: 1.9730 - accuracy: 0.9573WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 94/285 [========>.....................] - ETA: 7:26 - loss: 1.9533 - accuracy: 0.9571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 95/285 [=========>....................] - ETA: 7:24 - loss: 1.9348 - accuracy: 0.9569WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 96/285 [=========>....................] - ETA: 7:21 - loss: 1.9183 - accuracy: 0.9564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 97/285 [=========>....................] - ETA: 7:19 - loss: 1.8985 - accuracy: 0.9568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 98/285 [=========>....................] - ETA: 7:17 - loss: 1.8796 - accuracy: 0.9570WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 99/285 [=========>....................] - ETA: 7:14 - loss: 1.8649 - accuracy: 0.9571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/285 [=========>....................] - ETA: 7:12 - loss: 1.8501 - accuracy: 0.9566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "101/285 [=========>....................] - ETA: 7:09 - loss: 1.8318 - accuracy: 0.9570WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "102/285 [=========>....................] - ETA: 7:07 - loss: 1.8345 - accuracy: 0.9571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "103/285 [=========>....................] - ETA: 7:04 - loss: 1.8167 - accuracy: 0.9575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "104/285 [=========>....................] - ETA: 7:02 - loss: 1.8001 - accuracy: 0.9573WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "105/285 [==========>...................] - ETA: 6:59 - loss: 1.7829 - accuracy: 0.9577WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "106/285 [==========>...................] - ETA: 6:57 - loss: 1.7697 - accuracy: 0.9578WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "107/285 [==========>...................] - ETA: 6:54 - loss: 1.7532 - accuracy: 0.9582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "108/285 [==========>...................] - ETA: 6:52 - loss: 1.7371 - accuracy: 0.9586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "109/285 [==========>...................] - ETA: 6:50 - loss: 1.7211 - accuracy: 0.9590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "110/285 [==========>...................] - ETA: 6:47 - loss: 1.7063 - accuracy: 0.9591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "111/285 [==========>...................] - ETA: 6:45 - loss: 1.7315 - accuracy: 0.9589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "112/285 [==========>...................] - ETA: 6:42 - loss: 1.7161 - accuracy: 0.9593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "113/285 [==========>...................] - ETA: 6:40 - loss: 1.7009 - accuracy: 0.9596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "114/285 [===========>..................] - ETA: 6:38 - loss: 1.6885 - accuracy: 0.9594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "115/285 [===========>..................] - ETA: 6:35 - loss: 1.6738 - accuracy: 0.9598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "116/285 [===========>..................] - ETA: 6:33 - loss: 1.6598 - accuracy: 0.9599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "117/285 [===========>..................] - ETA: 6:30 - loss: 1.6534 - accuracy: 0.9599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "118/285 [===========>..................] - ETA: 6:28 - loss: 1.6396 - accuracy: 0.9603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "119/285 [===========>..................] - ETA: 6:26 - loss: 1.6258 - accuracy: 0.9606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "120/285 [===========>..................] - ETA: 6:23 - loss: 1.6123 - accuracy: 0.9609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "121/285 [===========>..................] - ETA: 6:21 - loss: 1.5992 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "122/285 [===========>..................] - ETA: 6:18 - loss: 1.5861 - accuracy: 0.9613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "123/285 [===========>..................] - ETA: 6:16 - loss: 1.5733 - accuracy: 0.9616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "124/285 [============>.................] - ETA: 6:14 - loss: 1.5607 - accuracy: 0.9619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "125/285 [============>.................] - ETA: 6:11 - loss: 1.5498 - accuracy: 0.9617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "126/285 [============>.................] - ETA: 6:09 - loss: 1.5382 - accuracy: 0.9618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "127/285 [============>.................] - ETA: 6:07 - loss: 1.5270 - accuracy: 0.9616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "128/285 [============>.................] - ETA: 6:04 - loss: 1.5162 - accuracy: 0.9612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "129/285 [============>.................] - ETA: 6:02 - loss: 1.5049 - accuracy: 0.9612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "130/285 [============>.................] - ETA: 5:59 - loss: 1.4944 - accuracy: 0.9611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "131/285 [============>.................] - ETA: 5:57 - loss: 1.4832 - accuracy: 0.9614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "132/285 [============>.................] - ETA: 5:54 - loss: 1.4755 - accuracy: 0.9616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "133/285 [=============>................] - ETA: 5:51 - loss: 1.4643 - accuracy: 0.9618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "134/285 [=============>................] - ETA: 5:49 - loss: 1.4534 - accuracy: 0.9621WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "135/285 [=============>................] - ETA: 5:47 - loss: 1.4431 - accuracy: 0.9622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "136/285 [=============>................] - ETA: 5:45 - loss: 1.4396 - accuracy: 0.9620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "137/285 [=============>................] - ETA: 5:43 - loss: 1.4300 - accuracy: 0.9620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "138/285 [=============>................] - ETA: 5:40 - loss: 1.4201 - accuracy: 0.9621WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "139/285 [=============>................] - ETA: 5:38 - loss: 1.4100 - accuracy: 0.9624WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "140/285 [=============>................] - ETA: 5:36 - loss: 1.4000 - accuracy: 0.9626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "141/285 [=============>................] - ETA: 5:33 - loss: 1.3906 - accuracy: 0.9627WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "142/285 [=============>................] - ETA: 5:32 - loss: 1.3819 - accuracy: 0.9625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "143/285 [==============>...............] - ETA: 5:29 - loss: 1.3798 - accuracy: 0.9625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "144/285 [==============>...............] - ETA: 5:27 - loss: 1.3703 - accuracy: 0.9628WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "145/285 [==============>...............] - ETA: 5:25 - loss: 1.3612 - accuracy: 0.9629WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "146/285 [==============>...............] - ETA: 5:23 - loss: 1.3520 - accuracy: 0.9631WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "147/285 [==============>...............] - ETA: 5:20 - loss: 1.3453 - accuracy: 0.9627WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "148/285 [==============>...............] - ETA: 5:18 - loss: 1.3362 - accuracy: 0.9630WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "149/285 [==============>...............] - ETA: 5:16 - loss: 1.3275 - accuracy: 0.9630WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/285 [==============>...............] - ETA: 5:14 - loss: 1.3186 - accuracy: 0.9633WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "151/285 [==============>...............] - ETA: 5:11 - loss: 1.3099 - accuracy: 0.9635WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "152/285 [===============>..............] - ETA: 5:09 - loss: 1.3012 - accuracy: 0.9637WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "153/285 [===============>..............] - ETA: 5:06 - loss: 1.2927 - accuracy: 0.9640WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "154/285 [===============>..............] - ETA: 5:04 - loss: 1.2844 - accuracy: 0.9642WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "155/285 [===============>..............] - ETA: 5:02 - loss: 1.2762 - accuracy: 0.9644WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "156/285 [===============>..............] - ETA: 4:59 - loss: 1.2721 - accuracy: 0.9641WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "157/285 [===============>..............] - ETA: 4:57 - loss: 1.2643 - accuracy: 0.9643WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "158/285 [===============>..............] - ETA: 4:55 - loss: 1.2565 - accuracy: 0.9643WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "159/285 [===============>..............] - ETA: 4:52 - loss: 1.2486 - accuracy: 0.9646WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "160/285 [===============>..............] - ETA: 4:50 - loss: 1.2408 - accuracy: 0.9648WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "161/285 [===============>..............] - ETA: 4:47 - loss: 1.2334 - accuracy: 0.9648WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "162/285 [================>.............] - ETA: 4:45 - loss: 1.2257 - accuracy: 0.9650WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "163/285 [================>.............] - ETA: 4:42 - loss: 1.2184 - accuracy: 0.9652WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "164/285 [================>.............] - ETA: 4:40 - loss: 1.2109 - accuracy: 0.9654WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "165/285 [================>.............] - ETA: 4:38 - loss: 1.2040 - accuracy: 0.9655WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "166/285 [================>.............] - ETA: 4:35 - loss: 1.1969 - accuracy: 0.9657WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "167/285 [================>.............] - ETA: 4:33 - loss: 1.1922 - accuracy: 0.9657WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "168/285 [================>.............] - ETA: 4:30 - loss: 1.1851 - accuracy: 0.9659WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "169/285 [================>.............] - ETA: 4:28 - loss: 1.1782 - accuracy: 0.9661WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "170/285 [================>.............] - ETA: 4:25 - loss: 1.1712 - accuracy: 0.9663WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "171/285 [=================>............] - ETA: 4:23 - loss: 1.1644 - accuracy: 0.9665WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "172/285 [=================>............] - ETA: 4:20 - loss: 1.1577 - accuracy: 0.9667WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "173/285 [=================>............] - ETA: 4:18 - loss: 1.1510 - accuracy: 0.9669WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "174/285 [=================>............] - ETA: 4:16 - loss: 1.1467 - accuracy: 0.9667WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "175/285 [=================>............] - ETA: 4:13 - loss: 1.1408 - accuracy: 0.9667WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "176/285 [=================>............] - ETA: 4:11 - loss: 1.1343 - accuracy: 0.9669WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "177/285 [=================>............] - ETA: 4:08 - loss: 1.1281 - accuracy: 0.9669WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "178/285 [=================>............] - ETA: 4:06 - loss: 1.1217 - accuracy: 0.9671WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "179/285 [=================>............] - ETA: 4:03 - loss: 1.1155 - accuracy: 0.9673WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "180/285 [=================>............] - ETA: 4:01 - loss: 1.1106 - accuracy: 0.9673WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "181/285 [==================>...........] - ETA: 3:59 - loss: 1.1050 - accuracy: 0.9671WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "182/285 [==================>...........] - ETA: 3:56 - loss: 1.0989 - accuracy: 0.9673WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "183/285 [==================>...........] - ETA: 3:54 - loss: 1.0930 - accuracy: 0.9675WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "184/285 [==================>...........] - ETA: 3:51 - loss: 1.0870 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "185/285 [==================>...........] - ETA: 3:49 - loss: 1.0814 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "186/285 [==================>...........] - ETA: 3:47 - loss: 1.0762 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "187/285 [==================>...........] - ETA: 3:44 - loss: 1.0706 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "188/285 [==================>...........] - ETA: 3:42 - loss: 1.0652 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "189/285 [==================>...........] - ETA: 3:40 - loss: 1.0597 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "190/285 [===================>..........] - ETA: 3:37 - loss: 1.0543 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "191/285 [===================>..........] - ETA: 3:35 - loss: 1.0491 - accuracy: 0.9676WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "192/285 [===================>..........] - ETA: 3:33 - loss: 1.0436 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "193/285 [===================>..........] - ETA: 3:30 - loss: 1.0382 - accuracy: 0.9679WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "194/285 [===================>..........] - ETA: 3:28 - loss: 1.0331 - accuracy: 0.9679WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "195/285 [===================>..........] - ETA: 3:26 - loss: 1.0284 - accuracy: 0.9679WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "196/285 [===================>..........] - ETA: 3:24 - loss: 1.0232 - accuracy: 0.9681WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "197/285 [===================>..........] - ETA: 3:21 - loss: 1.0180 - accuracy: 0.9682WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "198/285 [===================>..........] - ETA: 3:19 - loss: 1.0129 - accuracy: 0.9684WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "199/285 [===================>..........] - ETA: 3:17 - loss: 1.0081 - accuracy: 0.9684WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/285 [====================>.........] - ETA: 3:14 - loss: 1.0032 - accuracy: 0.9685WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "201/285 [====================>.........] - ETA: 3:12 - loss: 0.9982 - accuracy: 0.9687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "202/285 [====================>.........] - ETA: 3:10 - loss: 0.9933 - accuracy: 0.9689WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "203/285 [====================>.........] - ETA: 3:07 - loss: 0.9885 - accuracy: 0.9689WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "204/285 [====================>.........] - ETA: 3:05 - loss: 0.9837 - accuracy: 0.9690WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "205/285 [====================>.........] - ETA: 3:03 - loss: 0.9790 - accuracy: 0.9692WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "206/285 [====================>.........] - ETA: 3:01 - loss: 0.9743 - accuracy: 0.9693WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "207/285 [====================>.........] - ETA: 2:58 - loss: 0.9696 - accuracy: 0.9695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "208/285 [====================>.........] - ETA: 2:56 - loss: 0.9651 - accuracy: 0.9695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "209/285 [=====================>........] - ETA: 2:54 - loss: 0.9607 - accuracy: 0.9695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "210/285 [=====================>........] - ETA: 2:51 - loss: 0.9561 - accuracy: 0.9696WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "211/285 [=====================>........] - ETA: 2:49 - loss: 0.9517 - accuracy: 0.9696WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "212/285 [=====================>........] - ETA: 2:47 - loss: 0.9472 - accuracy: 0.9697WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "213/285 [=====================>........] - ETA: 2:45 - loss: 0.9427 - accuracy: 0.9699WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "214/285 [=====================>........] - ETA: 2:42 - loss: 0.9383 - accuracy: 0.9700WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "215/285 [=====================>........] - ETA: 2:40 - loss: 0.9340 - accuracy: 0.9702WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "216/285 [=====================>........] - ETA: 2:38 - loss: 0.9296 - accuracy: 0.9703WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "217/285 [=====================>........] - ETA: 2:36 - loss: 0.9254 - accuracy: 0.9704WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "218/285 [=====================>........] - ETA: 2:33 - loss: 0.9212 - accuracy: 0.9706WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "219/285 [======================>.......] - ETA: 2:31 - loss: 0.9172 - accuracy: 0.9706WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "220/285 [======================>.......] - ETA: 2:29 - loss: 0.9132 - accuracy: 0.9706WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "221/285 [======================>.......] - ETA: 2:27 - loss: 0.9091 - accuracy: 0.9707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "222/285 [======================>.......] - ETA: 2:24 - loss: 0.9067 - accuracy: 0.9707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "223/285 [======================>.......] - ETA: 2:22 - loss: 0.9036 - accuracy: 0.9704WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "224/285 [======================>.......] - ETA: 2:20 - loss: 0.8996 - accuracy: 0.9705WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "225/285 [======================>.......] - ETA: 2:17 - loss: 0.8956 - accuracy: 0.9707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "226/285 [======================>.......] - ETA: 2:15 - loss: 0.8922 - accuracy: 0.9706WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "227/285 [======================>.......] - ETA: 2:13 - loss: 0.8883 - accuracy: 0.9708WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "228/285 [=======================>......] - ETA: 2:10 - loss: 0.8844 - accuracy: 0.9709WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "229/285 [=======================>......] - ETA: 2:08 - loss: 0.8806 - accuracy: 0.9709WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "230/285 [=======================>......] - ETA: 2:06 - loss: 0.8768 - accuracy: 0.9710WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "231/285 [=======================>......] - ETA: 2:04 - loss: 0.8730 - accuracy: 0.9711WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "232/285 [=======================>......] - ETA: 2:01 - loss: 0.8692 - accuracy: 0.9713WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "233/285 [=======================>......] - ETA: 1:59 - loss: 0.8656 - accuracy: 0.9713WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "234/285 [=======================>......] - ETA: 1:57 - loss: 0.8619 - accuracy: 0.9714WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "235/285 [=======================>......] - ETA: 1:54 - loss: 0.8583 - accuracy: 0.9715WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "236/285 [=======================>......] - ETA: 1:52 - loss: 0.8546 - accuracy: 0.9716WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "237/285 [=======================>......] - ETA: 1:50 - loss: 0.8511 - accuracy: 0.9717WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "238/285 [========================>.....] - ETA: 1:47 - loss: 0.8475 - accuracy: 0.9719WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "239/285 [========================>.....] - ETA: 1:45 - loss: 0.8440 - accuracy: 0.9720WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "240/285 [========================>.....] - ETA: 1:43 - loss: 0.8404 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "241/285 [========================>.....] - ETA: 1:40 - loss: 0.8369 - accuracy: 0.9722WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "242/285 [========================>.....] - ETA: 1:38 - loss: 0.8335 - accuracy: 0.9723WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "243/285 [========================>.....] - ETA: 1:36 - loss: 0.8301 - accuracy: 0.9724WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "244/285 [========================>.....] - ETA: 1:34 - loss: 0.8268 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "245/285 [========================>.....] - ETA: 1:31 - loss: 0.8236 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "246/285 [========================>.....] - ETA: 1:29 - loss: 0.8203 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "247/285 [=========================>....] - ETA: 1:27 - loss: 0.8177 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "248/285 [=========================>....] - ETA: 1:24 - loss: 0.8144 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "249/285 [=========================>....] - ETA: 1:22 - loss: 0.8121 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/285 [=========================>....] - ETA: 1:20 - loss: 0.8095 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "251/285 [=========================>....] - ETA: 1:17 - loss: 0.8067 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "252/285 [=========================>....] - ETA: 1:15 - loss: 0.8036 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "253/285 [=========================>....] - ETA: 1:13 - loss: 0.8004 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "254/285 [=========================>....] - ETA: 1:11 - loss: 0.7984 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "255/285 [=========================>....] - ETA: 1:08 - loss: 0.7953 - accuracy: 0.9728WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "256/285 [=========================>....] - ETA: 1:06 - loss: 0.7922 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "257/285 [==========================>...] - ETA: 1:04 - loss: 0.7892 - accuracy: 0.9729WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "258/285 [==========================>...] - ETA: 1:01 - loss: 0.7863 - accuracy: 0.9728WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "259/285 [==========================>...] - ETA: 59s - loss: 0.7837 - accuracy: 0.9727 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "260/285 [==========================>...] - ETA: 57s - loss: 0.7807 - accuracy: 0.9728WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "261/285 [==========================>...] - ETA: 55s - loss: 0.7777 - accuracy: 0.9729WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "262/285 [==========================>...] - ETA: 52s - loss: 0.7752 - accuracy: 0.9729WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "263/285 [==========================>...] - ETA: 50s - loss: 0.7723 - accuracy: 0.9730WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "264/285 [==========================>...] - ETA: 48s - loss: 0.7695 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "265/285 [==========================>...] - ETA: 45s - loss: 0.7674 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "266/285 [===========================>..] - ETA: 43s - loss: 0.7648 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "267/285 [===========================>..] - ETA: 41s - loss: 0.7620 - accuracy: 0.9730WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "268/285 [===========================>..] - ETA: 38s - loss: 0.7592 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "269/285 [===========================>..] - ETA: 36s - loss: 0.7566 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "270/285 [===========================>..] - ETA: 34s - loss: 0.7538 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "271/285 [===========================>..] - ETA: 32s - loss: 0.7512 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "272/285 [===========================>..] - ETA: 29s - loss: 0.7485 - accuracy: 0.9733WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "273/285 [===========================>..] - ETA: 27s - loss: 0.7472 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "274/285 [===========================>..] - ETA: 25s - loss: 0.7449 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "275/285 [===========================>..] - ETA: 22s - loss: 0.7422 - accuracy: 0.9733WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "276/285 [============================>.] - ETA: 20s - loss: 0.7398 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "277/285 [============================>.] - ETA: 18s - loss: 0.7372 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "278/285 [============================>.] - ETA: 16s - loss: 0.7347 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "279/285 [============================>.] - ETA: 13s - loss: 0.7321 - accuracy: 0.9733WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "280/285 [============================>.] - ETA: 11s - loss: 0.7299 - accuracy: 0.9732WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "281/285 [============================>.] - ETA: 9s - loss: 0.7273 - accuracy: 0.9733 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "282/285 [============================>.] - ETA: 6s - loss: 0.7247 - accuracy: 0.9734WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "283/285 [============================>.] - ETA: 4s - loss: 0.7221 - accuracy: 0.9735WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "284/285 [============================>.] - ETA: 2s - loss: 0.7196 - accuracy: 0.9736WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.9737WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - 702s 2s/step - loss: 0.7171 - accuracy: 0.9737 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "MobileNet training took: 11.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "mobile_his = mobile_model.fit(train_generator,\n",
    "                              validation_data = validation_generator,\n",
    "                              batch_size = 32,\n",
    "                              epochs = 150,\n",
    "                              callbacks = [checkpoint, early])\n",
    "t2 = time.time()\n",
    "\n",
    "print('MobileNet training took: {:.2f} minutes.'.format((t2 - t1)/ 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.717077</td>\n",
       "      <td>0.973655</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.996993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.717077  0.973655  0.009079      0.996993"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mobile = pd.DataFrame(mobile_his.history)\n",
    "df_mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Với lượng dữ liệu lớn và tháo băng một phần mô hình pre-trained, MobileNet cho hiệu suất phân loại tương đối tốt, tuy nhiên kết quả có underfitting nhẹ, tương tự như phương pháp huấn luyện bằng lượng dữ liệu nhỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. InceptionV3 with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width_new, img_height_new = 299, 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception = applications.InceptionV3(weights = 'imagenet',\n",
    "                                     include_top = False,\n",
    "                                     input_shape = (img_width_new, img_height_new, 3))\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception.layers[: 6]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inception.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = Model(inputs = inception.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.compile(loss = 'binary_crossentropy',\n",
    "                        optimizer = 'adam',\n",
    "                        metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   rotation_range = 0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9110 images belonging to 2 classes.\n",
      "Found 2993 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (img_height_new, \n",
    "                                                                   img_width_new),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size = (img_height_new,\n",
    "                                                                       img_width_new),\n",
    "                                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('bike_car_inception.h5',\n",
    "                             monitor = 'val_loss',\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 1)\n",
    "\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0.001,\n",
    "                      mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/285 [..............................] - ETA: 1:18:50 - loss: 0.7006 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  2/285 [..............................] - ETA: 37:51 - loss: 12.5243 - accuracy: 0.5781 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  3/285 [..............................] - ETA: 36:20 - loss: 53.4137 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  4/285 [..............................] - ETA: 34:48 - loss: 45.2455 - accuracy: 0.5312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  5/285 [..............................] - ETA: 35:31 - loss: 38.3681 - accuracy: 0.5312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  6/285 [..............................] - ETA: 36:06 - loss: 32.1930 - accuracy: 0.5729WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  7/285 [..............................] - ETA: 35:37 - loss: 27.6231 - accuracy: 0.6295WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  8/285 [..............................] - ETA: 35:00 - loss: 24.2323 - accuracy: 0.6641WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  9/285 [..............................] - ETA: 34:41 - loss: 21.6246 - accuracy: 0.6875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 10/285 [>.............................] - ETA: 34:32 - loss: 19.5420 - accuracy: 0.7063WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 11/285 [>.............................] - ETA: 34:17 - loss: 17.8683 - accuracy: 0.7216WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 12/285 [>.............................] - ETA: 34:03 - loss: 16.5243 - accuracy: 0.7292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 13/285 [>.............................] - ETA: 33:40 - loss: 15.2763 - accuracy: 0.7380WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 14/285 [>.............................] - ETA: 33:18 - loss: 14.2488 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 15/285 [>.............................] - ETA: 33:02 - loss: 13.3475 - accuracy: 0.7354WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 16/285 [>.............................] - ETA: 32:43 - loss: 12.5509 - accuracy: 0.7383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 17/285 [>.............................] - ETA: 32:27 - loss: 11.8263 - accuracy: 0.7463WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 18/285 [>.............................] - ETA: 32:12 - loss: 11.1998 - accuracy: 0.7465WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 19/285 [=>............................] - ETA: 32:04 - loss: 10.6347 - accuracy: 0.7484WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 20/285 [=>............................] - ETA: 32:00 - loss: 10.1243 - accuracy: 0.7484WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 21/285 [=>............................] - ETA: 31:54 - loss: 9.6575 - accuracy: 0.7560 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 22/285 [=>............................] - ETA: 31:41 - loss: 9.2304 - accuracy: 0.7628WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/285 [=>............................] - ETA: 31:32 - loss: 8.8410 - accuracy: 0.7649WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 24/285 [=>............................] - ETA: 31:25 - loss: 8.4899 - accuracy: 0.7630WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 25/285 [=>............................] - ETA: 31:16 - loss: 8.1580 - accuracy: 0.7700WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 26/285 [=>............................] - ETA: 31:19 - loss: 7.8495 - accuracy: 0.7788WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 27/285 [=>............................] - ETA: 31:08 - loss: 7.5633 - accuracy: 0.7859WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 28/285 [=>............................] - ETA: 30:56 - loss: 7.3438 - accuracy: 0.7868WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 29/285 [==>...........................] - ETA: 30:43 - loss: 7.0992 - accuracy: 0.7909WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 30/285 [==>...........................] - ETA: 30:32 - loss: 6.8683 - accuracy: 0.7958WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 31/285 [==>...........................] - ETA: 30:24 - loss: 6.6709 - accuracy: 0.7954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 32/285 [==>...........................] - ETA: 30:16 - loss: 6.4669 - accuracy: 0.8008WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 33/285 [==>...........................] - ETA: 30:10 - loss: 6.2848 - accuracy: 0.8059WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 34/285 [==>...........................] - ETA: 29:59 - loss: 6.1146 - accuracy: 0.8070WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 35/285 [==>...........................] - ETA: 29:49 - loss: 5.9504 - accuracy: 0.8080WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 36/285 [==>...........................] - ETA: 29:39 - loss: 5.7953 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 37/285 [==>...........................] - ETA: 29:31 - loss: 5.6437 - accuracy: 0.8117WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 38/285 [===>..........................] - ETA: 29:25 - loss: 5.5005 - accuracy: 0.8150WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 39/285 [===>..........................] - ETA: 29:15 - loss: 5.3703 - accuracy: 0.8181WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 40/285 [===>..........................] - ETA: 29:06 - loss: 5.2420 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 41/285 [===>..........................] - ETA: 28:58 - loss: 5.1225 - accuracy: 0.8194WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 42/285 [===>..........................] - ETA: 28:49 - loss: 5.0075 - accuracy: 0.8185WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 43/285 [===>..........................] - ETA: 28:41 - loss: 4.9000 - accuracy: 0.8154WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 44/285 [===>..........................] - ETA: 28:39 - loss: 4.7947 - accuracy: 0.8182WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 45/285 [===>..........................] - ETA: 28:39 - loss: 4.6983 - accuracy: 0.8167WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 46/285 [===>..........................] - ETA: 28:41 - loss: 4.6057 - accuracy: 0.8159WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 47/285 [===>..........................] - ETA: 28:38 - loss: 4.5109 - accuracy: 0.8185WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 48/285 [====>.........................] - ETA: 28:32 - loss: 4.4212 - accuracy: 0.8203WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 49/285 [====>.........................] - ETA: 28:23 - loss: 4.3401 - accuracy: 0.8214WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 50/285 [====>.........................] - ETA: 28:13 - loss: 4.2599 - accuracy: 0.8225WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 51/285 [====>.........................] - ETA: 28:03 - loss: 4.1821 - accuracy: 0.8235WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 52/285 [====>.........................] - ETA: 27:54 - loss: 4.1040 - accuracy: 0.8263WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 53/285 [====>.........................] - ETA: 27:46 - loss: 4.0286 - accuracy: 0.8284WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 54/285 [====>.........................] - ETA: 27:37 - loss: 3.9596 - accuracy: 0.8281WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 55/285 [====>.........................] - ETA: 27:27 - loss: 3.8884 - accuracy: 0.8313WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 56/285 [====>.........................] - ETA: 27:18 - loss: 3.8201 - accuracy: 0.8337WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 57/285 [=====>........................] - ETA: 27:09 - loss: 3.7535 - accuracy: 0.8366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 58/285 [=====>........................] - ETA: 27:00 - loss: 3.6936 - accuracy: 0.8373WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 59/285 [=====>........................] - ETA: 26:55 - loss: 3.6329 - accuracy: 0.8390WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 60/285 [=====>........................] - ETA: 26:47 - loss: 3.5758 - accuracy: 0.8401WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 61/285 [=====>........................] - ETA: 26:38 - loss: 3.5278 - accuracy: 0.8412WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 62/285 [=====>........................] - ETA: 26:29 - loss: 3.4744 - accuracy: 0.8422WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 63/285 [=====>........................] - ETA: 26:21 - loss: 3.4194 - accuracy: 0.8447WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 64/285 [=====>........................] - ETA: 26:13 - loss: 3.3737 - accuracy: 0.8452WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 65/285 [=====>........................] - ETA: 26:06 - loss: 3.3265 - accuracy: 0.8457WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 66/285 [=====>........................] - ETA: 25:58 - loss: 3.2783 - accuracy: 0.8475WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 67/285 [======>.......................] - ETA: 25:50 - loss: 3.2315 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 68/285 [======>.......................] - ETA: 25:43 - loss: 3.1866 - accuracy: 0.8511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 69/285 [======>.......................] - ETA: 25:35 - loss: 3.1421 - accuracy: 0.8524WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 70/285 [======>.......................] - ETA: 25:26 - loss: 3.0984 - accuracy: 0.8540WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 71/285 [======>.......................] - ETA: 25:20 - loss: 3.0580 - accuracy: 0.8543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 72/285 [======>.......................] - ETA: 25:15 - loss: 3.0239 - accuracy: 0.8533WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 73/285 [======>.......................] - ETA: 25:10 - loss: 2.9832 - accuracy: 0.8553WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 74/285 [======>.......................] - ETA: 25:03 - loss: 2.9444 - accuracy: 0.8568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 75/285 [======>.......................] - ETA: 24:54 - loss: 2.9084 - accuracy: 0.8571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 76/285 [=======>......................] - ETA: 24:47 - loss: 2.8708 - accuracy: 0.8590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 77/285 [=======>......................] - ETA: 24:39 - loss: 2.8379 - accuracy: 0.8592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 78/285 [=======>......................] - ETA: 24:31 - loss: 2.8023 - accuracy: 0.8610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 79/285 [=======>......................] - ETA: 24:24 - loss: 2.7706 - accuracy: 0.8608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 80/285 [=======>......................] - ETA: 24:16 - loss: 2.7377 - accuracy: 0.8621WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 81/285 [=======>......................] - ETA: 24:08 - loss: 2.7048 - accuracy: 0.8638WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 82/285 [=======>......................] - ETA: 24:01 - loss: 2.6726 - accuracy: 0.8655WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 83/285 [=======>......................] - ETA: 23:53 - loss: 2.6419 - accuracy: 0.8663WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 84/285 [=======>......................] - ETA: 23:45 - loss: 2.6107 - accuracy: 0.8679WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 85/285 [=======>......................] - ETA: 23:38 - loss: 2.5810 - accuracy: 0.8691WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 86/285 [========>.....................] - ETA: 23:30 - loss: 2.5539 - accuracy: 0.8695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 87/285 [========>.....................] - ETA: 23:22 - loss: 2.5248 - accuracy: 0.8710WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 88/285 [========>.....................] - ETA: 23:15 - loss: 2.4987 - accuracy: 0.8714WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 89/285 [========>.....................] - ETA: 23:08 - loss: 2.4735 - accuracy: 0.8722WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 90/285 [========>.....................] - ETA: 23:01 - loss: 2.4475 - accuracy: 0.8733WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 91/285 [========>.....................] - ETA: 22:53 - loss: 2.4224 - accuracy: 0.8740WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 92/285 [========>.....................] - ETA: 22:46 - loss: 2.3964 - accuracy: 0.8753WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 93/285 [========>.....................] - ETA: 22:38 - loss: 2.3713 - accuracy: 0.8763WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 94/285 [========>.....................] - ETA: 22:31 - loss: 2.3478 - accuracy: 0.8770WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 95/285 [=========>....................] - ETA: 22:23 - loss: 2.3246 - accuracy: 0.8770WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 96/285 [=========>....................] - ETA: 22:16 - loss: 2.3018 - accuracy: 0.8776WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 97/285 [=========>....................] - ETA: 22:10 - loss: 2.2811 - accuracy: 0.8779WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 98/285 [=========>....................] - ETA: 22:05 - loss: 2.2584 - accuracy: 0.8788WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 99/285 [=========>....................] - ETA: 22:00 - loss: 2.2369 - accuracy: 0.8794WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "100/285 [=========>....................] - ETA: 21:59 - loss: 2.2162 - accuracy: 0.8797WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "101/285 [=========>....................] - ETA: 21:53 - loss: 2.1947 - accuracy: 0.8809WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "102/285 [=========>....................] - ETA: 21:46 - loss: 2.1734 - accuracy: 0.8820WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "103/285 [=========>....................] - ETA: 21:40 - loss: 2.1545 - accuracy: 0.8826WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "104/285 [=========>....................] - ETA: 21:34 - loss: 2.1339 - accuracy: 0.8837WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "105/285 [==========>...................] - ETA: 21:27 - loss: 2.1179 - accuracy: 0.8842WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "106/285 [==========>...................] - ETA: 21:19 - loss: 2.0985 - accuracy: 0.8853WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "107/285 [==========>...................] - ETA: 21:14 - loss: 2.0802 - accuracy: 0.8855WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "108/285 [==========>...................] - ETA: 21:07 - loss: 2.0613 - accuracy: 0.8863WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "109/285 [==========>...................] - ETA: 21:00 - loss: 2.0426 - accuracy: 0.8873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "110/285 [==========>...................] - ETA: 20:53 - loss: 2.0257 - accuracy: 0.8881WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "111/285 [==========>...................] - ETA: 20:45 - loss: 2.0084 - accuracy: 0.8888WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "112/285 [==========>...................] - ETA: 20:38 - loss: 1.9911 - accuracy: 0.8895WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "113/285 [==========>...................] - ETA: 20:30 - loss: 1.9746 - accuracy: 0.8902WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "114/285 [===========>..................] - ETA: 20:23 - loss: 1.9573 - accuracy: 0.8912WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "115/285 [===========>..................] - ETA: 20:16 - loss: 1.9412 - accuracy: 0.8918WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "116/285 [===========>..................] - ETA: 20:09 - loss: 1.9247 - accuracy: 0.8928WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "117/285 [===========>..................] - ETA: 20:01 - loss: 1.9085 - accuracy: 0.8937WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "118/285 [===========>..................] - ETA: 19:54 - loss: 1.8937 - accuracy: 0.8941WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "119/285 [===========>..................] - ETA: 19:47 - loss: 1.8786 - accuracy: 0.8944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "120/285 [===========>..................] - ETA: 19:39 - loss: 1.8647 - accuracy: 0.8951WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/285 [===========>..................] - ETA: 19:32 - loss: 1.8498 - accuracy: 0.8957WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "122/285 [===========>..................] - ETA: 19:25 - loss: 1.8361 - accuracy: 0.8960WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "123/285 [===========>..................] - ETA: 19:17 - loss: 1.8214 - accuracy: 0.8968WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "124/285 [============>.................] - ETA: 19:12 - loss: 1.8068 - accuracy: 0.8977WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "125/285 [============>.................] - ETA: 19:06 - loss: 1.7929 - accuracy: 0.8982WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "126/285 [============>.................] - ETA: 18:59 - loss: 1.7792 - accuracy: 0.8988WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "127/285 [============>.................] - ETA: 18:52 - loss: 1.7652 - accuracy: 0.8996WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "128/285 [============>.................] - ETA: 18:45 - loss: 1.7526 - accuracy: 0.8997WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "129/285 [============>.................] - ETA: 18:39 - loss: 1.7392 - accuracy: 0.9004WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "130/285 [============>.................] - ETA: 18:32 - loss: 1.7258 - accuracy: 0.9012WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "131/285 [============>.................] - ETA: 18:25 - loss: 1.7130 - accuracy: 0.9017WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "132/285 [============>.................] - ETA: 18:17 - loss: 1.7006 - accuracy: 0.9022WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "133/285 [=============>................] - ETA: 18:10 - loss: 1.6914 - accuracy: 0.9025WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "134/285 [=============>................] - ETA: 18:03 - loss: 1.6789 - accuracy: 0.9032WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "135/285 [=============>................] - ETA: 17:56 - loss: 1.6678 - accuracy: 0.9032WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "136/285 [=============>................] - ETA: 17:48 - loss: 1.6558 - accuracy: 0.9040WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "137/285 [=============>................] - ETA: 17:42 - loss: 1.6438 - accuracy: 0.9047WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "138/285 [=============>................] - ETA: 17:35 - loss: 1.6355 - accuracy: 0.9047WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "139/285 [=============>................] - ETA: 17:28 - loss: 1.6272 - accuracy: 0.9049WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "140/285 [=============>................] - ETA: 17:20 - loss: 1.6172 - accuracy: 0.9051WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "141/285 [=============>................] - ETA: 17:13 - loss: 1.6072 - accuracy: 0.9056WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "142/285 [=============>................] - ETA: 17:06 - loss: 1.5976 - accuracy: 0.9056WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "143/285 [==============>...............] - ETA: 16:59 - loss: 1.5867 - accuracy: 0.9060WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "144/285 [==============>...............] - ETA: 16:51 - loss: 1.5762 - accuracy: 0.9065WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "145/285 [==============>...............] - ETA: 16:44 - loss: 1.5657 - accuracy: 0.9069WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "146/285 [==============>...............] - ETA: 16:37 - loss: 1.5550 - accuracy: 0.9075WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "147/285 [==============>...............] - ETA: 16:30 - loss: 1.5448 - accuracy: 0.9082WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "148/285 [==============>...............] - ETA: 16:23 - loss: 1.5347 - accuracy: 0.9088WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "149/285 [==============>...............] - ETA: 16:16 - loss: 1.5248 - accuracy: 0.9092WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "150/285 [==============>...............] - ETA: 16:09 - loss: 1.5151 - accuracy: 0.9094WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "151/285 [==============>...............] - ETA: 16:01 - loss: 1.5060 - accuracy: 0.9091WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "152/285 [===============>..............] - ETA: 15:54 - loss: 1.4962 - accuracy: 0.9097WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "153/285 [===============>..............] - ETA: 15:48 - loss: 1.4871 - accuracy: 0.9101WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "154/285 [===============>..............] - ETA: 15:41 - loss: 1.4781 - accuracy: 0.9103WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "155/285 [===============>..............] - ETA: 15:34 - loss: 1.4689 - accuracy: 0.9107WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "156/285 [===============>..............] - ETA: 15:27 - loss: 1.4598 - accuracy: 0.9111WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "157/285 [===============>..............] - ETA: 15:20 - loss: 1.4506 - accuracy: 0.9116WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "158/285 [===============>..............] - ETA: 15:12 - loss: 1.4430 - accuracy: 0.9118WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "159/285 [===============>..............] - ETA: 15:05 - loss: 1.4349 - accuracy: 0.9121WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "160/285 [===============>..............] - ETA: 14:58 - loss: 1.4264 - accuracy: 0.9125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "161/285 [===============>..............] - ETA: 14:51 - loss: 1.4178 - accuracy: 0.9128WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "162/285 [================>.............] - ETA: 14:43 - loss: 1.4094 - accuracy: 0.9130WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "163/285 [================>.............] - ETA: 14:36 - loss: 1.4015 - accuracy: 0.9133WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "164/285 [================>.............] - ETA: 14:28 - loss: 1.3932 - accuracy: 0.9137WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "165/285 [================>.............] - ETA: 14:21 - loss: 1.3848 - accuracy: 0.9142WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "166/285 [================>.............] - ETA: 14:14 - loss: 1.3774 - accuracy: 0.9145WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "167/285 [================>.............] - ETA: 14:06 - loss: 1.3696 - accuracy: 0.9149WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "168/285 [================>.............] - ETA: 13:59 - loss: 1.3616 - accuracy: 0.9154WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "169/285 [================>.............] - ETA: 13:52 - loss: 1.3536 - accuracy: 0.9159WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "170/285 [================>.............] - ETA: 13:44 - loss: 1.3462 - accuracy: 0.9162WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "171/285 [=================>............] - ETA: 13:37 - loss: 1.3387 - accuracy: 0.9165WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "172/285 [=================>............] - ETA: 13:30 - loss: 1.3317 - accuracy: 0.9166WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "173/285 [=================>............] - ETA: 13:22 - loss: 1.3246 - accuracy: 0.9167WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "174/285 [=================>............] - ETA: 13:15 - loss: 1.3174 - accuracy: 0.9170WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "175/285 [=================>............] - ETA: 13:08 - loss: 1.3104 - accuracy: 0.9171WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "176/285 [=================>............] - ETA: 13:01 - loss: 1.3040 - accuracy: 0.9173WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "177/285 [=================>............] - ETA: 12:54 - loss: 1.2970 - accuracy: 0.9175WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "178/285 [=================>............] - ETA: 12:46 - loss: 1.2898 - accuracy: 0.9180WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "179/285 [=================>............] - ETA: 12:39 - loss: 1.2828 - accuracy: 0.9183WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "180/285 [=================>............] - ETA: 12:32 - loss: 1.2758 - accuracy: 0.9187WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "181/285 [==================>...........] - ETA: 12:24 - loss: 1.2689 - accuracy: 0.9192WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "182/285 [==================>...........] - ETA: 12:17 - loss: 1.2622 - accuracy: 0.9195WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "183/285 [==================>...........] - ETA: 12:10 - loss: 1.2556 - accuracy: 0.9197WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "184/285 [==================>...........] - ETA: 12:03 - loss: 1.2489 - accuracy: 0.9202WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "185/285 [==================>...........] - ETA: 11:56 - loss: 1.2422 - accuracy: 0.9206WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "186/285 [==================>...........] - ETA: 11:49 - loss: 1.2356 - accuracy: 0.9210WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "187/285 [==================>...........] - ETA: 11:41 - loss: 1.2292 - accuracy: 0.9215WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "188/285 [==================>...........] - ETA: 11:34 - loss: 1.2227 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "189/285 [==================>...........] - ETA: 11:26 - loss: 1.2184 - accuracy: 0.9220WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "190/285 [===================>..........] - ETA: 11:19 - loss: 1.2121 - accuracy: 0.9224WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "191/285 [===================>..........] - ETA: 11:12 - loss: 1.2066 - accuracy: 0.9224WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "192/285 [===================>..........] - ETA: 11:04 - loss: 1.2010 - accuracy: 0.9225WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "193/285 [===================>..........] - ETA: 10:57 - loss: 1.1956 - accuracy: 0.9228WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "194/285 [===================>..........] - ETA: 10:49 - loss: 1.1896 - accuracy: 0.9232WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "195/285 [===================>..........] - ETA: 10:42 - loss: 1.1836 - accuracy: 0.9236WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "196/285 [===================>..........] - ETA: 10:35 - loss: 1.1775 - accuracy: 0.9239WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "197/285 [===================>..........] - ETA: 10:27 - loss: 1.1719 - accuracy: 0.9242WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "198/285 [===================>..........] - ETA: 10:20 - loss: 1.1662 - accuracy: 0.9246WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "199/285 [===================>..........] - ETA: 10:13 - loss: 1.1604 - accuracy: 0.9249WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/285 [====================>.........] - ETA: 10:06 - loss: 1.1549 - accuracy: 0.9252WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "201/285 [====================>.........] - ETA: 9:59 - loss: 1.1495 - accuracy: 0.9254 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "202/285 [====================>.........] - ETA: 9:52 - loss: 1.1438 - accuracy: 0.9257WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "203/285 [====================>.........] - ETA: 9:45 - loss: 1.1383 - accuracy: 0.9261WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "204/285 [====================>.........] - ETA: 9:38 - loss: 1.1328 - accuracy: 0.9265WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "205/285 [====================>.........] - ETA: 9:31 - loss: 1.1276 - accuracy: 0.9265WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "206/285 [====================>.........] - ETA: 9:23 - loss: 1.1226 - accuracy: 0.9267WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "207/285 [====================>.........] - ETA: 9:16 - loss: 1.1172 - accuracy: 0.9271WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "208/285 [====================>.........] - ETA: 9:09 - loss: 1.1120 - accuracy: 0.9273WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "209/285 [=====================>........] - ETA: 9:01 - loss: 1.1068 - accuracy: 0.9275WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "210/285 [=====================>........] - ETA: 8:54 - loss: 1.1017 - accuracy: 0.9278WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "211/285 [=====================>........] - ETA: 8:47 - loss: 1.0969 - accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "212/285 [=====================>........] - ETA: 8:40 - loss: 1.0931 - accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "213/285 [=====================>........] - ETA: 8:32 - loss: 1.0886 - accuracy: 0.9277WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "214/285 [=====================>........] - ETA: 8:25 - loss: 1.0837 - accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "215/285 [=====================>........] - ETA: 8:18 - loss: 1.0787 - accuracy: 0.9282WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "216/285 [=====================>........] - ETA: 8:11 - loss: 1.0738 - accuracy: 0.9285WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "217/285 [=====================>........] - ETA: 8:04 - loss: 1.0690 - accuracy: 0.9289WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "218/285 [=====================>........] - ETA: 7:56 - loss: 1.0644 - accuracy: 0.9292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/285 [======================>.......] - ETA: 7:49 - loss: 1.0599 - accuracy: 0.9292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "220/285 [======================>.......] - ETA: 7:42 - loss: 1.0552 - accuracy: 0.9295WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "221/285 [======================>.......] - ETA: 7:35 - loss: 1.0510 - accuracy: 0.9297WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "222/285 [======================>.......] - ETA: 7:27 - loss: 1.0465 - accuracy: 0.9300WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "223/285 [======================>.......] - ETA: 7:20 - loss: 1.0420 - accuracy: 0.9304WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "224/285 [======================>.......] - ETA: 7:13 - loss: 1.0381 - accuracy: 0.9302WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "225/285 [======================>.......] - ETA: 7:06 - loss: 1.0336 - accuracy: 0.9306WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "226/285 [======================>.......] - ETA: 6:59 - loss: 1.0309 - accuracy: 0.9306WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "227/285 [======================>.......] - ETA: 6:51 - loss: 1.0268 - accuracy: 0.9306WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "228/285 [=======================>......] - ETA: 6:44 - loss: 1.0225 - accuracy: 0.9309WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "229/285 [=======================>......] - ETA: 6:37 - loss: 1.0182 - accuracy: 0.9311WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "230/285 [=======================>......] - ETA: 6:30 - loss: 1.0141 - accuracy: 0.9312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "231/285 [=======================>......] - ETA: 6:23 - loss: 1.0100 - accuracy: 0.9314WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "232/285 [=======================>......] - ETA: 6:16 - loss: 1.0059 - accuracy: 0.9317WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "233/285 [=======================>......] - ETA: 6:09 - loss: 1.0017 - accuracy: 0.9320WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "234/285 [=======================>......] - ETA: 6:02 - loss: 0.9975 - accuracy: 0.9322WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "235/285 [=======================>......] - ETA: 5:54 - loss: 0.9933 - accuracy: 0.9324WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "236/285 [=======================>......] - ETA: 5:47 - loss: 0.9892 - accuracy: 0.9327WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "237/285 [=======================>......] - ETA: 5:40 - loss: 0.9852 - accuracy: 0.9330WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "238/285 [========================>.....] - ETA: 5:33 - loss: 0.9816 - accuracy: 0.9332WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "239/285 [========================>.....] - ETA: 5:26 - loss: 0.9777 - accuracy: 0.9333WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "240/285 [========================>.....] - ETA: 5:19 - loss: 0.9737 - accuracy: 0.9336WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "241/285 [========================>.....] - ETA: 5:11 - loss: 0.9700 - accuracy: 0.9337WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "242/285 [========================>.....] - ETA: 5:04 - loss: 0.9660 - accuracy: 0.9340WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "243/285 [========================>.....] - ETA: 4:57 - loss: 0.9621 - accuracy: 0.9343WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "244/285 [========================>.....] - ETA: 4:50 - loss: 0.9583 - accuracy: 0.9346WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "245/285 [========================>.....] - ETA: 4:43 - loss: 0.9545 - accuracy: 0.9347WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "246/285 [========================>.....] - ETA: 4:36 - loss: 0.9507 - accuracy: 0.9350WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "247/285 [=========================>....] - ETA: 4:29 - loss: 0.9469 - accuracy: 0.9352WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "248/285 [=========================>....] - ETA: 4:22 - loss: 0.9432 - accuracy: 0.9355WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "249/285 [=========================>....] - ETA: 4:14 - loss: 0.9395 - accuracy: 0.9357WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "250/285 [=========================>....] - ETA: 4:07 - loss: 0.9360 - accuracy: 0.9359WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "251/285 [=========================>....] - ETA: 4:00 - loss: 0.9323 - accuracy: 0.9361WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "252/285 [=========================>....] - ETA: 3:53 - loss: 0.9286 - accuracy: 0.9364WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "253/285 [=========================>....] - ETA: 3:46 - loss: 0.9254 - accuracy: 0.9365WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "254/285 [=========================>....] - ETA: 3:39 - loss: 0.9220 - accuracy: 0.9366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "255/285 [=========================>....] - ETA: 3:32 - loss: 0.9185 - accuracy: 0.9368WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "256/285 [=========================>....] - ETA: 3:25 - loss: 0.9167 - accuracy: 0.9366WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "257/285 [==========================>...] - ETA: 3:17 - loss: 0.9132 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "258/285 [==========================>...] - ETA: 3:10 - loss: 0.9096 - accuracy: 0.9371WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "259/285 [==========================>...] - ETA: 3:03 - loss: 0.9062 - accuracy: 0.9374WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "260/285 [==========================>...] - ETA: 2:56 - loss: 0.9027 - accuracy: 0.9376WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "261/285 [==========================>...] - ETA: 2:49 - loss: 0.8995 - accuracy: 0.9377WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "262/285 [==========================>...] - ETA: 2:42 - loss: 0.8961 - accuracy: 0.9380WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "263/285 [==========================>...] - ETA: 2:35 - loss: 0.8930 - accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "264/285 [==========================>...] - ETA: 2:28 - loss: 0.8896 - accuracy: 0.9383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "265/285 [==========================>...] - ETA: 2:21 - loss: 0.8864 - accuracy: 0.9384WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "266/285 [===========================>..] - ETA: 2:14 - loss: 0.8832 - accuracy: 0.9386WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "267/285 [===========================>..] - ETA: 2:06 - loss: 0.8811 - accuracy: 0.9386WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "268/285 [===========================>..] - ETA: 1:59 - loss: 0.8782 - accuracy: 0.9387WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/285 [===========================>..] - ETA: 1:52 - loss: 0.8750 - accuracy: 0.9389WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "270/285 [===========================>..] - ETA: 1:45 - loss: 0.8718 - accuracy: 0.9392WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "271/285 [===========================>..] - ETA: 1:38 - loss: 0.8691 - accuracy: 0.9392WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "272/285 [===========================>..] - ETA: 1:31 - loss: 0.8661 - accuracy: 0.9393WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "273/285 [===========================>..] - ETA: 1:24 - loss: 0.8634 - accuracy: 0.9393WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "274/285 [===========================>..] - ETA: 1:17 - loss: 0.8605 - accuracy: 0.9394WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "275/285 [===========================>..] - ETA: 1:10 - loss: 0.8576 - accuracy: 0.9395WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "276/285 [============================>.] - ETA: 1:03 - loss: 0.8547 - accuracy: 0.9396WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "277/285 [============================>.] - ETA: 56s - loss: 0.8517 - accuracy: 0.9398 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "278/285 [============================>.] - ETA: 49s - loss: 0.8489 - accuracy: 0.9399WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "279/285 [============================>.] - ETA: 42s - loss: 0.8459 - accuracy: 0.9401WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "280/285 [============================>.] - ETA: 35s - loss: 0.8429 - accuracy: 0.9403WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "281/285 [============================>.] - ETA: 28s - loss: 0.8399 - accuracy: 0.9405WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "282/285 [============================>.] - ETA: 21s - loss: 0.8373 - accuracy: 0.9405WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "283/285 [============================>.] - ETA: 14s - loss: 0.8345 - accuracy: 0.9406WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "284/285 [============================>.] - ETA: 7s - loss: 0.8316 - accuracy: 0.9408 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.8289 - accuracy: 0.9409WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - 2153s 8s/step - loss: 0.8289 - accuracy: 0.9409 - val_loss: 0.0244 - val_accuracy: 0.9906\n",
      "InceptionV3 training took: 35.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "inception_his = inception_model.fit(train_generator,\n",
    "                                    validation_data = validation_generator,\n",
    "                                    batch_size = 32,\n",
    "                                    epochs = 150,\n",
    "                                    callbacks = [checkpoint, early])\n",
    "t2 = time.time()\n",
    "\n",
    "print('InceptionV3 training took: {:.2f} minutes.'.format((t2 - t1)/ 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.828854</td>\n",
       "      <td>0.940944</td>\n",
       "      <td>0.024449</td>\n",
       "      <td>0.990645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.828854  0.940944  0.024449      0.990645"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inception = pd.DataFrame(inception_his.history)\n",
    "df_inception.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- InceptionV3 huấn luyện với lượng dữ liệu lớn cho thấy kết quả tương đối tốt, thời gian huấn luyện nhanh hơn mô hình gốc, tuy nhiên có hiện tượng underfitting nhẹ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGG16 with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = applications.VGG16(weights = 'imagenet',\n",
    "                           include_top = False,\n",
    "                           input_shape = (img_width, img_height, 3))\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16.layers[:6]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = Model(inputs = vgg16.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.compile(loss = 'binary_crossentropy',\n",
    "                    optimizer = 'adam',\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   rotation_range = 30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9110 images belonging to 2 classes.\n",
      "Found 2993 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (img_height,\n",
    "                                                                   img_width),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size = (img_height,\n",
    "                                                                       img_width),\n",
    "                                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('bike_car_vgg16.h5',\n",
    "                                  monitor = 'val_loss',\n",
    "                                  save_best_only = True,\n",
    "                                  save_weights_only = False,\n",
    "                                  mode = 'auto',\n",
    "                                  save_freq = 1)\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0.001,\n",
    "                      mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/285 [..............................] - ETA: 35:20 - loss: 0.6634 - accuracy: 0.5938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  2/285 [..............................] - ETA: 28:30 - loss: 13.4566 - accuracy: 0.5938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  3/285 [..............................] - ETA: 30:11 - loss: 9.2323 - accuracy: 0.5729 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  4/285 [..............................] - ETA: 30:57 - loss: 8.4376 - accuracy: 0.5859WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  5/285 [..............................] - ETA: 30:35 - loss: 13.1632 - accuracy: 0.5250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  6/285 [..............................] - ETA: 30:17 - loss: 11.0845 - accuracy: 0.5312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  7/285 [..............................] - ETA: 30:06 - loss: 9.5967 - accuracy: 0.5446 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  8/285 [..............................] - ETA: 30:12 - loss: 8.4827 - accuracy: 0.5469WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  9/285 [..............................] - ETA: 30:14 - loss: 7.6155 - accuracy: 0.5486WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 10/285 [>.............................] - ETA: 30:09 - loss: 6.9254 - accuracy: 0.5312WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 11/285 [>.............................] - ETA: 30:02 - loss: 6.3592 - accuracy: 0.5284WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 12/285 [>.............................] - ETA: 29:54 - loss: 5.8876 - accuracy: 0.5286WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 13/285 [>.............................] - ETA: 29:47 - loss: 5.4880 - accuracy: 0.5240WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 14/285 [>.............................] - ETA: 29:42 - loss: 5.1453 - accuracy: 0.5290WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 15/285 [>.............................] - ETA: 29:37 - loss: 4.8479 - accuracy: 0.5375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 16/285 [>.............................] - ETA: 29:30 - loss: 4.5872 - accuracy: 0.5430WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 17/285 [>.............................] - ETA: 29:23 - loss: 4.3581 - accuracy: 0.5478WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 18/285 [>.............................] - ETA: 29:15 - loss: 4.1551 - accuracy: 0.5486WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 19/285 [=>............................] - ETA: 29:08 - loss: 3.9732 - accuracy: 0.5461WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 20/285 [=>............................] - ETA: 29:01 - loss: 3.8090 - accuracy: 0.5500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 21/285 [=>............................] - ETA: 28:54 - loss: 3.6607 - accuracy: 0.5461WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 22/285 [=>............................] - ETA: 28:47 - loss: 3.5255 - accuracy: 0.5497WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 23/285 [=>............................] - ETA: 28:42 - loss: 3.4014 - accuracy: 0.5543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 24/285 [=>............................] - ETA: 28:46 - loss: 3.2905 - accuracy: 0.5508WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 25/285 [=>............................] - ETA: 28:45 - loss: 3.1857 - accuracy: 0.5525WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 26/285 [=>............................] - ETA: 28:39 - loss: 3.0865 - accuracy: 0.5589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 27/285 [=>............................] - ETA: 28:33 - loss: 2.9980 - accuracy: 0.5590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 28/285 [=>............................] - ETA: 28:26 - loss: 2.9157 - accuracy: 0.5547WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 29/285 [==>...........................] - ETA: 28:20 - loss: 2.8386 - accuracy: 0.5593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 30/285 [==>...........................] - ETA: 28:14 - loss: 2.7661 - accuracy: 0.5635WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 31/285 [==>...........................] - ETA: 28:08 - loss: 2.6987 - accuracy: 0.5645WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 32/285 [==>...........................] - ETA: 28:02 - loss: 2.6352 - accuracy: 0.5645WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 33/285 [==>...........................] - ETA: 27:56 - loss: 2.5760 - accuracy: 0.5634WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 34/285 [==>...........................] - ETA: 27:49 - loss: 2.5205 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 35/285 [==>...........................] - ETA: 27:43 - loss: 2.4685 - accuracy: 0.5589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 36/285 [==>...........................] - ETA: 27:37 - loss: 2.4193 - accuracy: 0.5582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 37/285 [==>...........................] - ETA: 27:37 - loss: 2.3738 - accuracy: 0.5574WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 38/285 [===>..........................] - ETA: 27:36 - loss: 2.3286 - accuracy: 0.5584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 39/285 [===>..........................] - ETA: 27:36 - loss: 2.2863 - accuracy: 0.5593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 40/285 [===>..........................] - ETA: 27:36 - loss: 2.2442 - accuracy: 0.5641WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 41/285 [===>..........................] - ETA: 27:45 - loss: 2.2083 - accuracy: 0.5617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 42/285 [===>..........................] - ETA: 27:56 - loss: 2.1738 - accuracy: 0.5588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 43/285 [===>..........................] - ETA: 28:02 - loss: 2.1388 - accuracy: 0.5589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 44/285 [===>..........................] - ETA: 28:02 - loss: 2.1051 - accuracy: 0.5597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 45/285 [===>..........................] - ETA: 27:59 - loss: 2.0729 - accuracy: 0.5618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 46/285 [===>..........................] - ETA: 27:56 - loss: 2.0431 - accuracy: 0.5598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 47/285 [===>..........................] - ETA: 27:54 - loss: 2.0137 - accuracy: 0.5618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 48/285 [====>.........................] - ETA: 27:50 - loss: 1.9856 - accuracy: 0.5632WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 49/285 [====>.........................] - ETA: 27:45 - loss: 1.9589 - accuracy: 0.5631WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 50/285 [====>.........................] - ETA: 27:38 - loss: 1.9339 - accuracy: 0.5612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 51/285 [====>.........................] - ETA: 27:33 - loss: 1.9087 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 52/285 [====>.........................] - ETA: 27:26 - loss: 1.8851 - accuracy: 0.5631WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 53/285 [====>.........................] - ETA: 27:19 - loss: 1.8629 - accuracy: 0.5607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 54/285 [====>.........................] - ETA: 27:13 - loss: 1.8407 - accuracy: 0.5619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 55/285 [====>.........................] - ETA: 27:06 - loss: 1.8200 - accuracy: 0.5602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 56/285 [====>.........................] - ETA: 27:01 - loss: 1.7998 - accuracy: 0.5597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 57/285 [=====>........................] - ETA: 26:57 - loss: 1.7803 - accuracy: 0.5598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 58/285 [=====>........................] - ETA: 26:52 - loss: 1.7613 - accuracy: 0.5603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 59/285 [=====>........................] - ETA: 26:48 - loss: 1.7431 - accuracy: 0.5604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 60/285 [=====>........................] - ETA: 26:43 - loss: 1.7256 - accuracy: 0.5594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 61/285 [=====>........................] - ETA: 26:36 - loss: 1.7084 - accuracy: 0.5620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 62/285 [=====>........................] - ETA: 26:28 - loss: 1.6923 - accuracy: 0.5590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 63/285 [=====>........................] - ETA: 26:20 - loss: 1.6764 - accuracy: 0.5585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 64/285 [=====>........................] - ETA: 26:12 - loss: 1.6610 - accuracy: 0.5586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 65/285 [=====>........................] - ETA: 26:05 - loss: 1.6459 - accuracy: 0.5591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 66/285 [=====>........................] - ETA: 25:59 - loss: 1.6316 - accuracy: 0.5568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 67/285 [======>.......................] - ETA: 25:53 - loss: 1.6172 - accuracy: 0.5583WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 68/285 [======>.......................] - ETA: 25:48 - loss: 1.6034 - accuracy: 0.5584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 69/285 [======>.......................] - ETA: 25:42 - loss: 1.5906 - accuracy: 0.5562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 70/285 [======>.......................] - ETA: 25:36 - loss: 1.5781 - accuracy: 0.5536WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 71/285 [======>.......................] - ETA: 25:31 - loss: 1.5656 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 72/285 [======>.......................] - ETA: 25:24 - loss: 1.5533 - accuracy: 0.5543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 73/285 [======>.......................] - ETA: 25:18 - loss: 1.5412 - accuracy: 0.5548WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 74/285 [======>.......................] - ETA: 25:12 - loss: 1.5293 - accuracy: 0.5553WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 75/285 [======>.......................] - ETA: 25:05 - loss: 1.5182 - accuracy: 0.5537WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 76/285 [=======>......................] - ETA: 24:58 - loss: 1.5067 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 77/285 [=======>......................] - ETA: 24:50 - loss: 1.4967 - accuracy: 0.5540WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 78/285 [=======>......................] - ETA: 24:42 - loss: 1.4864 - accuracy: 0.5537WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 79/285 [=======>......................] - ETA: 24:34 - loss: 1.4763 - accuracy: 0.5542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 80/285 [=======>......................] - ETA: 24:28 - loss: 1.4662 - accuracy: 0.5547WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 81/285 [=======>......................] - ETA: 24:21 - loss: 1.4565 - accuracy: 0.5544WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 82/285 [=======>......................] - ETA: 24:14 - loss: 1.4470 - accuracy: 0.5545WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 83/285 [=======>......................] - ETA: 24:08 - loss: 1.4377 - accuracy: 0.5550WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 84/285 [=======>......................] - ETA: 24:03 - loss: 1.4287 - accuracy: 0.5554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 85/285 [=======>......................] - ETA: 23:58 - loss: 1.4199 - accuracy: 0.5555WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 86/285 [========>.....................] - ETA: 23:52 - loss: 1.4111 - accuracy: 0.5563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 87/285 [========>.....................] - ETA: 23:46 - loss: 1.4024 - accuracy: 0.5571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 88/285 [========>.....................] - ETA: 23:39 - loss: 1.3944 - accuracy: 0.5561WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 89/285 [========>.....................] - ETA: 23:34 - loss: 1.3860 - accuracy: 0.5569WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 90/285 [========>.....................] - ETA: 23:28 - loss: 1.3782 - accuracy: 0.5562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 91/285 [========>.....................] - ETA: 23:22 - loss: 1.3703 - accuracy: 0.5573WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 92/285 [========>.....................] - ETA: 23:15 - loss: 1.3630 - accuracy: 0.5574WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 93/285 [========>.....................] - ETA: 23:09 - loss: 1.3561 - accuracy: 0.5565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 94/285 [========>.....................] - ETA: 23:02 - loss: 1.3490 - accuracy: 0.5562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 95/285 [=========>....................] - ETA: 22:55 - loss: 1.3421 - accuracy: 0.5566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 96/285 [=========>....................] - ETA: 22:48 - loss: 1.3352 - accuracy: 0.5570WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 97/285 [=========>....................] - ETA: 22:41 - loss: 1.3288 - accuracy: 0.5561WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 98/285 [=========>....................] - ETA: 22:34 - loss: 1.3227 - accuracy: 0.5552WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/285 [=========>....................] - ETA: 22:26 - loss: 1.3163 - accuracy: 0.5549WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "100/285 [=========>....................] - ETA: 22:19 - loss: 1.3105 - accuracy: 0.5531WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "101/285 [=========>....................] - ETA: 22:11 - loss: 1.3043 - accuracy: 0.5529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "102/285 [=========>....................] - ETA: 22:04 - loss: 1.2982 - accuracy: 0.5542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "103/285 [=========>....................] - ETA: 21:57 - loss: 1.2921 - accuracy: 0.5552WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "104/285 [=========>....................] - ETA: 21:50 - loss: 1.2862 - accuracy: 0.5562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "105/285 [==========>...................] - ETA: 21:44 - loss: 1.2805 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "106/285 [==========>...................] - ETA: 21:36 - loss: 1.2749 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "107/285 [==========>...................] - ETA: 21:29 - loss: 1.2695 - accuracy: 0.5540WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "108/285 [==========>...................] - ETA: 21:22 - loss: 1.2641 - accuracy: 0.5541WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "109/285 [==========>...................] - ETA: 21:15 - loss: 1.2588 - accuracy: 0.5539WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "110/285 [==========>...................] - ETA: 21:09 - loss: 1.2535 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "111/285 [==========>...................] - ETA: 21:02 - loss: 1.2482 - accuracy: 0.5566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "112/285 [==========>...................] - ETA: 20:55 - loss: 1.2432 - accuracy: 0.5566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "113/285 [==========>...................] - ETA: 20:48 - loss: 1.2382 - accuracy: 0.5567WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "114/285 [===========>..................] - ETA: 20:41 - loss: 1.2335 - accuracy: 0.5562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "115/285 [===========>..................] - ETA: 20:34 - loss: 1.2321 - accuracy: 0.5543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "116/285 [===========>..................] - ETA: 20:27 - loss: 1.2275 - accuracy: 0.5544WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "117/285 [===========>..................] - ETA: 20:20 - loss: 1.2226 - accuracy: 0.5556WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "118/285 [===========>..................] - ETA: 20:13 - loss: 1.2185 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "119/285 [===========>..................] - ETA: 20:06 - loss: 1.2138 - accuracy: 0.5565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "120/285 [===========>..................] - ETA: 19:58 - loss: 1.2101 - accuracy: 0.5560WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "121/285 [===========>..................] - ETA: 19:51 - loss: 1.2046 - accuracy: 0.5579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "122/285 [===========>..................] - ETA: 19:44 - loss: 1.2005 - accuracy: 0.5581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "123/285 [===========>..................] - ETA: 19:38 - loss: 1.1978 - accuracy: 0.5564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "124/285 [============>.................] - ETA: 19:31 - loss: 1.1937 - accuracy: 0.5559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "125/285 [============>.................] - ETA: 19:24 - loss: 1.1896 - accuracy: 0.5570WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "126/285 [============>.................] - ETA: 19:17 - loss: 1.1855 - accuracy: 0.5588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "127/285 [============>.................] - ETA: 19:10 - loss: 1.1818 - accuracy: 0.5583WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "128/285 [============>.................] - ETA: 19:03 - loss: 1.1776 - accuracy: 0.5591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "129/285 [============>.................] - ETA: 18:56 - loss: 1.1740 - accuracy: 0.5594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "130/285 [============>.................] - ETA: 18:48 - loss: 1.1704 - accuracy: 0.5584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "131/285 [============>.................] - ETA: 18:41 - loss: 1.1669 - accuracy: 0.5570WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "132/285 [============>.................] - ETA: 18:34 - loss: 1.1633 - accuracy: 0.5566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "133/285 [=============>................] - ETA: 18:27 - loss: 1.1598 - accuracy: 0.5564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "134/285 [=============>................] - ETA: 18:19 - loss: 1.1563 - accuracy: 0.5571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "135/285 [=============>................] - ETA: 18:12 - loss: 1.1528 - accuracy: 0.5579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "136/285 [=============>................] - ETA: 18:05 - loss: 1.1494 - accuracy: 0.5581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "137/285 [=============>................] - ETA: 17:58 - loss: 1.1460 - accuracy: 0.5577WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "138/285 [=============>................] - ETA: 17:51 - loss: 1.1427 - accuracy: 0.5589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "139/285 [=============>................] - ETA: 17:44 - loss: 1.1394 - accuracy: 0.5591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "140/285 [=============>................] - ETA: 17:37 - loss: 1.1362 - accuracy: 0.5589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "141/285 [=============>................] - ETA: 17:30 - loss: 1.1329 - accuracy: 0.5596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "142/285 [=============>................] - ETA: 17:24 - loss: 1.1298 - accuracy: 0.5599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "143/285 [==============>...............] - ETA: 17:17 - loss: 1.1275 - accuracy: 0.5592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "144/285 [==============>...............] - ETA: 17:10 - loss: 1.1386 - accuracy: 0.5588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "145/285 [==============>...............] - ETA: 17:03 - loss: 1.1372 - accuracy: 0.5578WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "146/285 [==============>...............] - ETA: 16:56 - loss: 1.1342 - accuracy: 0.5576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "147/285 [==============>...............] - ETA: 16:50 - loss: 1.1316 - accuracy: 0.5563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "148/285 [==============>...............] - ETA: 16:42 - loss: 1.1287 - accuracy: 0.5557WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "149/285 [==============>...............] - ETA: 16:35 - loss: 1.1257 - accuracy: 0.5558WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "150/285 [==============>...............] - ETA: 16:28 - loss: 1.1228 - accuracy: 0.5556WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "151/285 [==============>...............] - ETA: 16:20 - loss: 1.1199 - accuracy: 0.5559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "152/285 [===============>..............] - ETA: 16:13 - loss: 1.1171 - accuracy: 0.5559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "153/285 [===============>..............] - ETA: 16:06 - loss: 1.1143 - accuracy: 0.5560WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "154/285 [===============>..............] - ETA: 15:59 - loss: 1.1114 - accuracy: 0.5568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "155/285 [===============>..............] - ETA: 15:52 - loss: 1.1082 - accuracy: 0.5579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "156/285 [===============>..............] - ETA: 15:44 - loss: 1.1056 - accuracy: 0.5579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "157/285 [===============>..............] - ETA: 15:37 - loss: 1.1029 - accuracy: 0.5581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "158/285 [===============>..............] - ETA: 15:30 - loss: 1.1035 - accuracy: 0.5581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "159/285 [===============>..............] - ETA: 15:23 - loss: 1.1016 - accuracy: 0.5568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "160/285 [===============>..............] - ETA: 15:16 - loss: 1.0992 - accuracy: 0.5559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "161/285 [===============>..............] - ETA: 15:09 - loss: 1.0967 - accuracy: 0.5557WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "162/285 [================>.............] - ETA: 15:02 - loss: 1.0940 - accuracy: 0.5563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "163/285 [================>.............] - ETA: 14:55 - loss: 1.1069 - accuracy: 0.5571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "164/285 [================>.............] - ETA: 14:48 - loss: 1.1051 - accuracy: 0.5566WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "165/285 [================>.............] - ETA: 14:41 - loss: 1.1917 - accuracy: 0.5564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "166/285 [================>.............] - ETA: 14:35 - loss: 1.1889 - accuracy: 0.5559WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "167/285 [================>.............] - ETA: 14:28 - loss: 1.1860 - accuracy: 0.5554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "168/285 [================>.............] - ETA: 14:21 - loss: 1.1830 - accuracy: 0.5554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "169/285 [================>.............] - ETA: 14:14 - loss: 1.1802 - accuracy: 0.5551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "170/285 [================>.............] - ETA: 14:06 - loss: 1.1773 - accuracy: 0.5550WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "171/285 [=================>............] - ETA: 13:59 - loss: 1.1759 - accuracy: 0.5539WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "172/285 [=================>............] - ETA: 13:52 - loss: 1.1732 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "173/285 [=================>............] - ETA: 13:45 - loss: 1.1705 - accuracy: 0.5518WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "174/285 [=================>............] - ETA: 13:37 - loss: 1.1676 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "175/285 [=================>............] - ETA: 13:30 - loss: 1.1647 - accuracy: 0.5532WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "176/285 [=================>............] - ETA: 13:22 - loss: 1.1620 - accuracy: 0.5531WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "177/285 [=================>............] - ETA: 13:15 - loss: 1.1595 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "178/285 [=================>............] - ETA: 13:08 - loss: 1.1569 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "179/285 [=================>............] - ETA: 13:01 - loss: 1.1542 - accuracy: 0.5531WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "180/285 [=================>............] - ETA: 12:54 - loss: 1.1516 - accuracy: 0.5533WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "181/285 [==================>...........] - ETA: 12:47 - loss: 1.1491 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "182/285 [==================>...........] - ETA: 12:40 - loss: 1.1466 - accuracy: 0.5525WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "183/285 [==================>...........] - ETA: 12:33 - loss: 1.1441 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "184/285 [==================>...........] - ETA: 12:26 - loss: 1.1416 - accuracy: 0.5523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "185/285 [==================>...........] - ETA: 12:18 - loss: 1.1392 - accuracy: 0.5519WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "186/285 [==================>...........] - ETA: 12:11 - loss: 1.1367 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "187/285 [==================>...........] - ETA: 12:03 - loss: 1.1344 - accuracy: 0.5525WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "188/285 [==================>...........] - ETA: 11:56 - loss: 1.1320 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "189/285 [==================>...........] - ETA: 11:48 - loss: 1.1297 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "190/285 [===================>..........] - ETA: 11:41 - loss: 1.1276 - accuracy: 0.5523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "191/285 [===================>..........] - ETA: 11:33 - loss: 1.1253 - accuracy: 0.5522WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "192/285 [===================>..........] - ETA: 11:26 - loss: 1.1229 - accuracy: 0.5526WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "193/285 [===================>..........] - ETA: 11:19 - loss: 1.1206 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "194/285 [===================>..........] - ETA: 11:12 - loss: 1.1183 - accuracy: 0.5532WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "195/285 [===================>..........] - ETA: 11:05 - loss: 1.1160 - accuracy: 0.5534WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "196/285 [===================>..........] - ETA: 10:57 - loss: 1.1138 - accuracy: 0.5529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/285 [===================>..........] - ETA: 10:50 - loss: 1.1116 - accuracy: 0.5533WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "198/285 [===================>..........] - ETA: 10:42 - loss: 1.1095 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "199/285 [===================>..........] - ETA: 10:35 - loss: 1.1075 - accuracy: 0.5517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/285 [====================>.........] - ETA: 10:28 - loss: 1.1054 - accuracy: 0.5520WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "201/285 [====================>.........] - ETA: 10:20 - loss: 1.1033 - accuracy: 0.5521WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "202/285 [====================>.........] - ETA: 10:13 - loss: 1.1013 - accuracy: 0.5518WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "203/285 [====================>.........] - ETA: 10:06 - loss: 1.0992 - accuracy: 0.5520WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "204/285 [====================>.........] - ETA: 9:58 - loss: 1.0973 - accuracy: 0.5516 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "205/285 [====================>.........] - ETA: 9:51 - loss: 1.0952 - accuracy: 0.5521WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "206/285 [====================>.........] - ETA: 9:44 - loss: 1.0932 - accuracy: 0.5522WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "207/285 [====================>.........] - ETA: 9:37 - loss: 1.0911 - accuracy: 0.5528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "208/285 [====================>.........] - ETA: 9:29 - loss: 1.0891 - accuracy: 0.5529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "209/285 [=====================>........] - ETA: 9:22 - loss: 1.0868 - accuracy: 0.5538WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "210/285 [=====================>........] - ETA: 9:15 - loss: 1.0851 - accuracy: 0.5536WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "211/285 [=====================>........] - ETA: 9:07 - loss: 1.0828 - accuracy: 0.5545WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "212/285 [=====================>........] - ETA: 9:00 - loss: 1.0809 - accuracy: 0.5547WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "213/285 [=====================>........] - ETA: 8:52 - loss: 1.0794 - accuracy: 0.5541WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "214/285 [=====================>........] - ETA: 8:45 - loss: 1.0774 - accuracy: 0.5545WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "215/285 [=====================>........] - ETA: 8:38 - loss: 1.0757 - accuracy: 0.5542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "216/285 [=====================>........] - ETA: 8:30 - loss: 1.0740 - accuracy: 0.5535WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "217/285 [=====================>........] - ETA: 8:23 - loss: 1.0723 - accuracy: 0.5530WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "218/285 [=====================>........] - ETA: 8:16 - loss: 1.0706 - accuracy: 0.5529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "219/285 [======================>.......] - ETA: 8:08 - loss: 1.0689 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "220/285 [======================>.......] - ETA: 8:01 - loss: 1.0670 - accuracy: 0.5534WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "221/285 [======================>.......] - ETA: 7:54 - loss: 1.0653 - accuracy: 0.5537WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "222/285 [======================>.......] - ETA: 7:46 - loss: 1.0635 - accuracy: 0.5539WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "223/285 [======================>.......] - ETA: 7:39 - loss: 1.0619 - accuracy: 0.5534WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "224/285 [======================>.......] - ETA: 7:32 - loss: 1.0603 - accuracy: 0.5534WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "225/285 [======================>.......] - ETA: 7:25 - loss: 1.0586 - accuracy: 0.5532WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "226/285 [======================>.......] - ETA: 7:17 - loss: 1.0570 - accuracy: 0.5530WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "227/285 [======================>.......] - ETA: 7:10 - loss: 1.0554 - accuracy: 0.5527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "228/285 [=======================>......] - ETA: 7:02 - loss: 1.0539 - accuracy: 0.5522WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "229/285 [=======================>......] - ETA: 6:55 - loss: 1.0523 - accuracy: 0.5519WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "230/285 [=======================>......] - ETA: 6:48 - loss: 1.0508 - accuracy: 0.5511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "231/285 [=======================>......] - ETA: 6:40 - loss: 1.0493 - accuracy: 0.5511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "232/285 [=======================>......] - ETA: 6:33 - loss: 1.0477 - accuracy: 0.5512WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "233/285 [=======================>......] - ETA: 6:26 - loss: 1.0461 - accuracy: 0.5516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "234/285 [=======================>......] - ETA: 6:18 - loss: 1.0446 - accuracy: 0.5519WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "235/285 [=======================>......] - ETA: 6:11 - loss: 1.0430 - accuracy: 0.5523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "236/285 [=======================>......] - ETA: 6:04 - loss: 1.0415 - accuracy: 0.5523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "237/285 [=======================>......] - ETA: 5:56 - loss: 1.0401 - accuracy: 0.5521WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "238/285 [========================>.....] - ETA: 5:49 - loss: 1.0386 - accuracy: 0.5516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "239/285 [========================>.....] - ETA: 5:41 - loss: 1.0372 - accuracy: 0.5518WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "240/285 [========================>.....] - ETA: 5:34 - loss: 1.0357 - accuracy: 0.5517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "241/285 [========================>.....] - ETA: 5:26 - loss: 1.0347 - accuracy: 0.5515WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "242/285 [========================>.....] - ETA: 5:19 - loss: 1.0333 - accuracy: 0.5515WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "243/285 [========================>.....] - ETA: 5:12 - loss: 1.0319 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "244/285 [========================>.....] - ETA: 5:04 - loss: 1.0306 - accuracy: 0.5508WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "245/285 [========================>.....] - ETA: 4:57 - loss: 1.0293 - accuracy: 0.5501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "246/285 [========================>.....] - ETA: 4:49 - loss: 1.0279 - accuracy: 0.5501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/285 [=========================>....] - ETA: 4:42 - loss: 1.0265 - accuracy: 0.5502WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "248/285 [=========================>....] - ETA: 4:35 - loss: 1.0252 - accuracy: 0.5498WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "249/285 [=========================>....] - ETA: 4:27 - loss: 1.0238 - accuracy: 0.5503WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "250/285 [=========================>....] - ETA: 4:20 - loss: 1.0225 - accuracy: 0.5499WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "251/285 [=========================>....] - ETA: 4:12 - loss: 1.0211 - accuracy: 0.5506WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "252/285 [=========================>....] - ETA: 4:05 - loss: 1.0197 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "253/285 [=========================>....] - ETA: 3:58 - loss: 1.0184 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "254/285 [=========================>....] - ETA: 3:50 - loss: 1.0171 - accuracy: 0.5510WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "255/285 [=========================>....] - ETA: 3:43 - loss: 1.0158 - accuracy: 0.5509WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "256/285 [=========================>....] - ETA: 3:35 - loss: 1.0145 - accuracy: 0.5516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "257/285 [==========================>...] - ETA: 3:28 - loss: 1.0132 - accuracy: 0.5517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "258/285 [==========================>...] - ETA: 3:21 - loss: 1.0120 - accuracy: 0.5513WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "259/285 [==========================>...] - ETA: 3:13 - loss: 1.0107 - accuracy: 0.5515WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "260/285 [==========================>...] - ETA: 3:06 - loss: 1.0095 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "261/285 [==========================>...] - ETA: 2:58 - loss: 1.0082 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "262/285 [==========================>...] - ETA: 2:51 - loss: 1.0070 - accuracy: 0.5513WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "263/285 [==========================>...] - ETA: 2:44 - loss: 1.0058 - accuracy: 0.5513WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "264/285 [==========================>...] - ETA: 2:36 - loss: 1.0046 - accuracy: 0.5514WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "265/285 [==========================>...] - ETA: 2:29 - loss: 1.0034 - accuracy: 0.5510WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "266/285 [===========================>..] - ETA: 2:21 - loss: 1.0021 - accuracy: 0.5518WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "267/285 [===========================>..] - ETA: 2:14 - loss: 1.0010 - accuracy: 0.5517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "268/285 [===========================>..] - ETA: 2:06 - loss: 0.9998 - accuracy: 0.5515WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "269/285 [===========================>..] - ETA: 1:59 - loss: 0.9986 - accuracy: 0.5519WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "270/285 [===========================>..] - ETA: 1:51 - loss: 0.9974 - accuracy: 0.5520WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "271/285 [===========================>..] - ETA: 1:44 - loss: 0.9963 - accuracy: 0.5520WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "272/285 [===========================>..] - ETA: 1:37 - loss: 0.9952 - accuracy: 0.5516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "273/285 [===========================>..] - ETA: 1:29 - loss: 0.9941 - accuracy: 0.5516WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "274/285 [===========================>..] - ETA: 1:22 - loss: 0.9930 - accuracy: 0.5513WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "275/285 [===========================>..] - ETA: 1:14 - loss: 0.9919 - accuracy: 0.5512WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "276/285 [============================>.] - ETA: 1:07 - loss: 0.9908 - accuracy: 0.5512WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "277/285 [============================>.] - ETA: 59s - loss: 0.9898 - accuracy: 0.5509 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "278/285 [============================>.] - ETA: 52s - loss: 0.9887 - accuracy: 0.5506WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "279/285 [============================>.] - ETA: 44s - loss: 0.9876 - accuracy: 0.5507WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "280/285 [============================>.] - ETA: 37s - loss: 0.9865 - accuracy: 0.5509WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "281/285 [============================>.] - ETA: 29s - loss: 0.9854 - accuracy: 0.5510WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "282/285 [============================>.] - ETA: 22s - loss: 0.9844 - accuracy: 0.5506WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "283/285 [============================>.] - ETA: 14s - loss: 0.9834 - accuracy: 0.5507WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "284/285 [============================>.] - ETA: 7s - loss: 0.9823 - accuracy: 0.5508 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.9814 - accuracy: 0.5501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - 2429s 9s/step - loss: 0.9814 - accuracy: 0.5501 - val_loss: 0.6965 - val_accuracy: 0.4009\n",
      "VGG16 training took: 40.49 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "vgg16_his = vgg16_model.fit(train_generator,\n",
    "                            validation_data = validation_generator,\n",
    "                            batch_size = 32,\n",
    "                            epochs = 150,\n",
    "                            callbacks = [checkpoint, early])\n",
    "t2 = time.time()\n",
    "print('VGG16 training took: {:.2f} minutes.'.format((t2 - t1)/ 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981383</td>\n",
       "      <td>0.550055</td>\n",
       "      <td>0.696544</td>\n",
       "      <td>0.400936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.981383  0.550055  0.696544      0.400936"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vgg16 = pd.DataFrame(vgg16_his.history)\n",
    "df_vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGG 16 trong trường hợp này cho kết quả khá tệ. Độ chính xác thấp hơn hẳn so với trường hợp dùng dữ liệu nhỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ResNet50 with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50 = applications.ResNet50(weights = 'imagenet',\n",
    "                                 include_top = False,\n",
    "                                 input_shape = (img_width, img_height, 3))\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet50.layers[:6]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resnet50.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = Model(inputs = resnet50.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.compile(loss = 'binary_crossentropy',\n",
    "                       optimizer = 'adam',\n",
    "                       metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   rotation_range = 30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9110 images belonging to 2 classes.\n",
      "Found 2993 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (img_height,\n",
    "                                                                   img_width),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size = (img_height,\n",
    "                                                                       img_width),\n",
    "                                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('bike_car_resnet50.h5',\n",
    "                                  monitor = 'val_loss',\n",
    "                                  save_best_only = True,\n",
    "                                  save_weights_only = False,\n",
    "                                  mode = 'auto',\n",
    "                                  save_freq = 1)\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0.001,\n",
    "                      mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/285 [..............................] - ETA: 1:01:00 - loss: 0.9805 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  2/285 [..............................] - ETA: 37:35 - loss: 5.6642 - accuracy: 0.5000  WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  3/285 [..............................] - ETA: 35:21 - loss: 42.4443 - accuracy: 0.5104WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  4/285 [..............................] - ETA: 34:12 - loss: 32.8843 - accuracy: 0.5781WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  5/285 [..............................] - ETA: 33:22 - loss: 27.6169 - accuracy: 0.6125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  6/285 [..............................] - ETA: 32:49 - loss: 23.2217 - accuracy: 0.6562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  7/285 [..............................] - ETA: 32:20 - loss: 20.0287 - accuracy: 0.6920WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  8/285 [..............................] - ETA: 32:02 - loss: 17.8826 - accuracy: 0.7148WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "  9/285 [..............................] - ETA: 32:09 - loss: 15.9475 - accuracy: 0.7292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 10/285 [>.............................] - ETA: 32:21 - loss: 14.9196 - accuracy: 0.7281WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 11/285 [>.............................] - ETA: 32:11 - loss: 13.7599 - accuracy: 0.7301WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 12/285 [>.............................] - ETA: 31:59 - loss: 12.6244 - accuracy: 0.7500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 13/285 [>.............................] - ETA: 31:43 - loss: 11.6861 - accuracy: 0.7596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 14/285 [>.............................] - ETA: 31:29 - loss: 10.8752 - accuracy: 0.7679WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 15/285 [>.............................] - ETA: 31:16 - loss: 10.2012 - accuracy: 0.7750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 16/285 [>.............................] - ETA: 31:05 - loss: 9.6002 - accuracy: 0.7734 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 17/285 [>.............................] - ETA: 30:55 - loss: 9.0946 - accuracy: 0.7776WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 18/285 [>.............................] - ETA: 30:44 - loss: 8.5986 - accuracy: 0.7847WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 19/285 [=>............................] - ETA: 30:33 - loss: 8.2159 - accuracy: 0.7878WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 20/285 [=>............................] - ETA: 30:23 - loss: 7.8366 - accuracy: 0.7844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 21/285 [=>............................] - ETA: 30:14 - loss: 7.5316 - accuracy: 0.7872WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 22/285 [=>............................] - ETA: 30:06 - loss: 7.2119 - accuracy: 0.7884WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 23/285 [=>............................] - ETA: 29:57 - loss: 6.9591 - accuracy: 0.7894WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 24/285 [=>............................] - ETA: 29:48 - loss: 6.6820 - accuracy: 0.7930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 25/285 [=>............................] - ETA: 29:39 - loss: 6.4493 - accuracy: 0.7937WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 26/285 [=>............................] - ETA: 29:30 - loss: 6.2959 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 27/285 [=>............................] - ETA: 29:21 - loss: 6.0702 - accuracy: 0.7986WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 28/285 [=>............................] - ETA: 29:13 - loss: 5.8588 - accuracy: 0.8047WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 29/285 [==>...........................] - ETA: 29:05 - loss: 6.3968 - accuracy: 0.8071WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 30/285 [==>...........................] - ETA: 28:56 - loss: 6.1968 - accuracy: 0.8052WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 31/285 [==>...........................] - ETA: 28:48 - loss: 6.1323 - accuracy: 0.8095WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 32/285 [==>...........................] - ETA: 28:40 - loss: 6.0572 - accuracy: 0.8105WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 33/285 [==>...........................] - ETA: 28:32 - loss: 5.9753 - accuracy: 0.8097WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 34/285 [==>...........................] - ETA: 28:24 - loss: 5.8338 - accuracy: 0.8061WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 35/285 [==>...........................] - ETA: 28:16 - loss: 5.7023 - accuracy: 0.8054WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 36/285 [==>...........................] - ETA: 28:08 - loss: 5.5837 - accuracy: 0.7977WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 37/285 [==>...........................] - ETA: 28:02 - loss: 5.4461 - accuracy: 0.7990WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 38/285 [===>..........................] - ETA: 28:01 - loss: 5.3405 - accuracy: 0.7928WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 39/285 [===>..........................] - ETA: 28:09 - loss: 5.2452 - accuracy: 0.7901WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 40/285 [===>..........................] - ETA: 28:07 - loss: 5.1278 - accuracy: 0.7883WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 41/285 [===>..........................] - ETA: 27:59 - loss: 5.0173 - accuracy: 0.7851WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 42/285 [===>..........................] - ETA: 27:59 - loss: 4.9112 - accuracy: 0.7827WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 43/285 [===>..........................] - ETA: 27:58 - loss: 4.8048 - accuracy: 0.7827WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 44/285 [===>..........................] - ETA: 27:49 - loss: 4.7112 - accuracy: 0.7784WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 45/285 [===>..........................] - ETA: 27:41 - loss: 4.6954 - accuracy: 0.7757WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 46/285 [===>..........................] - ETA: 27:33 - loss: 4.6228 - accuracy: 0.7731WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 47/285 [===>..........................] - ETA: 27:24 - loss: 4.5347 - accuracy: 0.7719WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 48/285 [====>.........................] - ETA: 27:16 - loss: 4.4474 - accuracy: 0.7734WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 49/285 [====>.........................] - ETA: 27:08 - loss: 4.3646 - accuracy: 0.7749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 50/285 [====>.........................] - ETA: 27:00 - loss: 4.2862 - accuracy: 0.7750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 51/285 [====>.........................] - ETA: 26:52 - loss: 4.2103 - accuracy: 0.7745WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 52/285 [====>.........................] - ETA: 26:45 - loss: 4.1390 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 53/285 [====>.........................] - ETA: 26:37 - loss: 4.0675 - accuracy: 0.7754WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 54/285 [====>.........................] - ETA: 26:29 - loss: 4.0229 - accuracy: 0.7749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 55/285 [====>.........................] - ETA: 26:21 - loss: 3.9552 - accuracy: 0.7767WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 56/285 [====>.........................] - ETA: 26:13 - loss: 3.8918 - accuracy: 0.7779WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 57/285 [=====>........................] - ETA: 26:05 - loss: 3.8324 - accuracy: 0.7780WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 58/285 [=====>........................] - ETA: 25:57 - loss: 3.7886 - accuracy: 0.7786WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 59/285 [=====>........................] - ETA: 25:49 - loss: 3.7359 - accuracy: 0.7807WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 60/285 [=====>........................] - ETA: 25:42 - loss: 3.6803 - accuracy: 0.7823WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 61/285 [=====>........................] - ETA: 25:34 - loss: 3.6230 - accuracy: 0.7853WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 62/285 [=====>........................] - ETA: 25:26 - loss: 3.5769 - accuracy: 0.7858WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 63/285 [=====>........................] - ETA: 25:19 - loss: 3.5234 - accuracy: 0.7882WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 64/285 [=====>........................] - ETA: 25:11 - loss: 3.4730 - accuracy: 0.7891WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 65/285 [=====>........................] - ETA: 25:03 - loss: 3.4342 - accuracy: 0.7894WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 66/285 [=====>........................] - ETA: 24:56 - loss: 3.3931 - accuracy: 0.7893WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 67/285 [======>.......................] - ETA: 24:49 - loss: 3.3479 - accuracy: 0.7892WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 68/285 [======>.......................] - ETA: 24:41 - loss: 3.3018 - accuracy: 0.7909WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/285 [======>.......................] - ETA: 24:34 - loss: 3.2605 - accuracy: 0.7921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 70/285 [======>.......................] - ETA: 24:28 - loss: 3.2192 - accuracy: 0.7920WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 71/285 [======>.......................] - ETA: 24:19 - loss: 3.1787 - accuracy: 0.7923WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 72/285 [======>.......................] - ETA: 24:11 - loss: 3.1396 - accuracy: 0.7921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 73/285 [======>.......................] - ETA: 24:02 - loss: 3.1002 - accuracy: 0.7932WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 74/285 [======>.......................] - ETA: 23:53 - loss: 3.0622 - accuracy: 0.7939WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 75/285 [======>.......................] - ETA: 23:45 - loss: 3.0280 - accuracy: 0.7942WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 76/285 [=======>......................] - ETA: 23:36 - loss: 3.0006 - accuracy: 0.7936WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 77/285 [=======>......................] - ETA: 23:28 - loss: 2.9659 - accuracy: 0.7942WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 78/285 [=======>......................] - ETA: 23:20 - loss: 2.9307 - accuracy: 0.7957WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 79/285 [=======>......................] - ETA: 23:11 - loss: 2.8982 - accuracy: 0.7967WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 80/285 [=======>......................] - ETA: 23:03 - loss: 2.8650 - accuracy: 0.7988WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 81/285 [=======>......................] - ETA: 22:55 - loss: 2.8338 - accuracy: 0.7998WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 82/285 [=======>......................] - ETA: 22:47 - loss: 2.8044 - accuracy: 0.8003WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 83/285 [=======>......................] - ETA: 22:39 - loss: 2.7744 - accuracy: 0.8008WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 84/285 [=======>......................] - ETA: 22:31 - loss: 2.7441 - accuracy: 0.8025WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 85/285 [=======>......................] - ETA: 22:24 - loss: 2.7143 - accuracy: 0.8037WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 86/285 [========>.....................] - ETA: 22:18 - loss: 2.6852 - accuracy: 0.8049WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 87/285 [========>.....................] - ETA: 22:11 - loss: 2.6599 - accuracy: 0.8039WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 88/285 [========>.....................] - ETA: 22:05 - loss: 2.6340 - accuracy: 0.8043WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 89/285 [========>.....................] - ETA: 21:58 - loss: 2.6077 - accuracy: 0.8055WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 90/285 [========>.....................] - ETA: 21:50 - loss: 2.5802 - accuracy: 0.8069WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 91/285 [========>.....................] - ETA: 21:43 - loss: 2.5608 - accuracy: 0.8063WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 92/285 [========>.....................] - ETA: 21:36 - loss: 2.5343 - accuracy: 0.8081WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 93/285 [========>.....................] - ETA: 21:28 - loss: 2.5090 - accuracy: 0.8091WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 94/285 [========>.....................] - ETA: 21:21 - loss: 2.4911 - accuracy: 0.8092WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 95/285 [=========>....................] - ETA: 21:15 - loss: 2.4665 - accuracy: 0.8109WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 96/285 [=========>....................] - ETA: 21:07 - loss: 2.4433 - accuracy: 0.8118WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 97/285 [=========>....................] - ETA: 21:01 - loss: 2.4465 - accuracy: 0.8119WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 98/285 [=========>....................] - ETA: 20:54 - loss: 2.4241 - accuracy: 0.8131WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      " 99/285 [=========>....................] - ETA: 20:47 - loss: 2.4060 - accuracy: 0.8138WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "100/285 [=========>....................] - ETA: 20:40 - loss: 2.3867 - accuracy: 0.8144WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "101/285 [=========>....................] - ETA: 20:33 - loss: 2.3662 - accuracy: 0.8153WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "102/285 [=========>....................] - ETA: 20:26 - loss: 2.3561 - accuracy: 0.8153WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "103/285 [=========>....................] - ETA: 20:19 - loss: 2.3375 - accuracy: 0.8149WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "104/285 [=========>....................] - ETA: 20:12 - loss: 2.3311 - accuracy: 0.8143WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "105/285 [==========>...................] - ETA: 20:06 - loss: 2.3130 - accuracy: 0.8149WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "106/285 [==========>...................] - ETA: 19:59 - loss: 2.2942 - accuracy: 0.8152WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "107/285 [==========>...................] - ETA: 19:52 - loss: 2.2763 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "108/285 [==========>...................] - ETA: 19:45 - loss: 2.2576 - accuracy: 0.8160WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "109/285 [==========>...................] - ETA: 19:38 - loss: 2.2403 - accuracy: 0.8159WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "110/285 [==========>...................] - ETA: 19:31 - loss: 2.2217 - accuracy: 0.8162WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "111/285 [==========>...................] - ETA: 19:24 - loss: 2.2037 - accuracy: 0.8167WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "112/285 [==========>...................] - ETA: 19:19 - loss: 2.1860 - accuracy: 0.8175WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "113/285 [==========>...................] - ETA: 19:13 - loss: 2.1686 - accuracy: 0.8189WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "114/285 [===========>..................] - ETA: 19:07 - loss: 2.1522 - accuracy: 0.8188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "115/285 [===========>..................] - ETA: 19:01 - loss: 2.1357 - accuracy: 0.8190WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "116/285 [===========>..................] - ETA: 18:54 - loss: 2.1196 - accuracy: 0.8192WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "117/285 [===========>..................] - ETA: 18:47 - loss: 2.1069 - accuracy: 0.8194WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "118/285 [===========>..................] - ETA: 18:40 - loss: 2.0907 - accuracy: 0.8202WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "119/285 [===========>..................] - ETA: 18:33 - loss: 2.0745 - accuracy: 0.8212WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "120/285 [===========>..................] - ETA: 18:26 - loss: 2.0587 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "121/285 [===========>..................] - ETA: 18:20 - loss: 2.0428 - accuracy: 0.8228WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "122/285 [===========>..................] - ETA: 18:13 - loss: 2.0301 - accuracy: 0.8233WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "123/285 [===========>..................] - ETA: 18:06 - loss: 2.0157 - accuracy: 0.8237WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "124/285 [============>.................] - ETA: 17:59 - loss: 2.0025 - accuracy: 0.8236WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "125/285 [============>.................] - ETA: 17:52 - loss: 1.9952 - accuracy: 0.8235WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "126/285 [============>.................] - ETA: 17:46 - loss: 1.9839 - accuracy: 0.8237WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "127/285 [============>.................] - ETA: 17:39 - loss: 1.9719 - accuracy: 0.8241WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "128/285 [============>.................] - ETA: 17:32 - loss: 1.9585 - accuracy: 0.8247WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "129/285 [============>.................] - ETA: 17:26 - loss: 1.9456 - accuracy: 0.8249WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "130/285 [============>.................] - ETA: 17:20 - loss: 1.9322 - accuracy: 0.8255WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "131/285 [============>.................] - ETA: 17:13 - loss: 1.9191 - accuracy: 0.8266WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "132/285 [============>.................] - ETA: 17:07 - loss: 1.9061 - accuracy: 0.8272WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "133/285 [=============>................] - ETA: 17:00 - loss: 1.8934 - accuracy: 0.8280WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "134/285 [=============>................] - ETA: 16:53 - loss: 1.8807 - accuracy: 0.8288WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "135/285 [=============>................] - ETA: 16:46 - loss: 1.8696 - accuracy: 0.8294WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "136/285 [=============>................] - ETA: 16:40 - loss: 1.8573 - accuracy: 0.8300WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "137/285 [=============>................] - ETA: 16:33 - loss: 1.8458 - accuracy: 0.8305WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "138/285 [=============>................] - ETA: 16:26 - loss: 1.8346 - accuracy: 0.8306WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "139/285 [=============>................] - ETA: 16:19 - loss: 1.8239 - accuracy: 0.8307WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "140/285 [=============>................] - ETA: 16:12 - loss: 1.8126 - accuracy: 0.8313WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "141/285 [=============>................] - ETA: 16:06 - loss: 1.8008 - accuracy: 0.8320WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "142/285 [=============>................] - ETA: 15:57 - loss: 1.7931 - accuracy: 0.8322WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "143/285 [==============>...............] - ETA: 15:50 - loss: 1.7825 - accuracy: 0.8327WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "144/285 [==============>...............] - ETA: 15:43 - loss: 1.7712 - accuracy: 0.8336WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "145/285 [==============>...............] - ETA: 15:37 - loss: 1.7654 - accuracy: 0.8341WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "146/285 [==============>...............] - ETA: 15:30 - loss: 1.7550 - accuracy: 0.8346WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "147/285 [==============>...............] - ETA: 15:23 - loss: 1.7457 - accuracy: 0.8345WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "148/285 [==============>...............] - ETA: 15:17 - loss: 1.7355 - accuracy: 0.8352WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "149/285 [==============>...............] - ETA: 15:10 - loss: 1.7253 - accuracy: 0.8359WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "150/285 [==============>...............] - ETA: 15:03 - loss: 1.7144 - accuracy: 0.8367WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "151/285 [==============>...............] - ETA: 14:57 - loss: 1.7042 - accuracy: 0.8374WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "152/285 [===============>..............] - ETA: 14:50 - loss: 1.6936 - accuracy: 0.8383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "153/285 [===============>..............] - ETA: 14:43 - loss: 1.6835 - accuracy: 0.8389WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "154/285 [===============>..............] - ETA: 14:36 - loss: 1.6735 - accuracy: 0.8398WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "155/285 [===============>..............] - ETA: 14:29 - loss: 1.6634 - accuracy: 0.8406WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "156/285 [===============>..............] - ETA: 14:23 - loss: 1.6548 - accuracy: 0.8408WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "157/285 [===============>..............] - ETA: 14:16 - loss: 1.6472 - accuracy: 0.8410WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "158/285 [===============>..............] - ETA: 14:10 - loss: 1.6384 - accuracy: 0.8415WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "159/285 [===============>..............] - ETA: 14:03 - loss: 1.6309 - accuracy: 0.8415WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "160/285 [===============>..............] - ETA: 13:57 - loss: 1.6214 - accuracy: 0.8423WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "161/285 [===============>..............] - ETA: 13:50 - loss: 1.6121 - accuracy: 0.8429WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "162/285 [================>.............] - ETA: 13:44 - loss: 1.6038 - accuracy: 0.8434WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "163/285 [================>.............] - ETA: 13:37 - loss: 1.5948 - accuracy: 0.8442WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "164/285 [================>.............] - ETA: 13:31 - loss: 1.5873 - accuracy: 0.8444WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "165/285 [================>.............] - ETA: 13:25 - loss: 1.5784 - accuracy: 0.8452WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "166/285 [================>.............] - ETA: 13:18 - loss: 1.5700 - accuracy: 0.8455WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/285 [================>.............] - ETA: 13:11 - loss: 1.5613 - accuracy: 0.8459WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "168/285 [================>.............] - ETA: 13:04 - loss: 1.5538 - accuracy: 0.8464WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "169/285 [================>.............] - ETA: 12:58 - loss: 1.5460 - accuracy: 0.8464WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "170/285 [================>.............] - ETA: 12:51 - loss: 1.5380 - accuracy: 0.8466WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "171/285 [=================>............] - ETA: 12:44 - loss: 1.5301 - accuracy: 0.8471WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "172/285 [=================>............] - ETA: 12:37 - loss: 1.5225 - accuracy: 0.8477WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "173/285 [=================>............] - ETA: 12:30 - loss: 1.5150 - accuracy: 0.8480WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "174/285 [=================>............] - ETA: 12:23 - loss: 1.5068 - accuracy: 0.8487WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "175/285 [=================>............] - ETA: 12:17 - loss: 1.4990 - accuracy: 0.8494WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "176/285 [=================>............] - ETA: 12:10 - loss: 1.4922 - accuracy: 0.8497WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "177/285 [=================>............] - ETA: 12:03 - loss: 1.4844 - accuracy: 0.8500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "178/285 [=================>............] - ETA: 11:56 - loss: 1.4764 - accuracy: 0.8509WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "179/285 [=================>............] - ETA: 11:50 - loss: 1.4683 - accuracy: 0.8517WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "180/285 [=================>............] - ETA: 11:44 - loss: 1.4609 - accuracy: 0.8520WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "181/285 [==================>...........] - ETA: 11:38 - loss: 1.4538 - accuracy: 0.8521WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "182/285 [==================>...........] - ETA: 11:31 - loss: 1.4497 - accuracy: 0.8524WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "183/285 [==================>...........] - ETA: 11:24 - loss: 1.4455 - accuracy: 0.8527WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "184/285 [==================>...........] - ETA: 11:18 - loss: 1.4396 - accuracy: 0.8532WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "185/285 [==================>...........] - ETA: 11:12 - loss: 1.4331 - accuracy: 0.8536WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "186/285 [==================>...........] - ETA: 11:06 - loss: 1.4258 - accuracy: 0.8543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "187/285 [==================>...........] - ETA: 10:59 - loss: 1.4215 - accuracy: 0.8542WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "188/285 [==================>...........] - ETA: 10:52 - loss: 1.4155 - accuracy: 0.8543WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "189/285 [==================>...........] - ETA: 10:46 - loss: 1.4097 - accuracy: 0.8544WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "190/285 [===================>..........] - ETA: 10:40 - loss: 1.4033 - accuracy: 0.8547WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "191/285 [===================>..........] - ETA: 10:33 - loss: 1.4017 - accuracy: 0.8546WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "192/285 [===================>..........] - ETA: 10:27 - loss: 1.3967 - accuracy: 0.8549WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "193/285 [===================>..........] - ETA: 10:20 - loss: 1.3916 - accuracy: 0.8548WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "194/285 [===================>..........] - ETA: 10:13 - loss: 1.3862 - accuracy: 0.8554WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "195/285 [===================>..........] - ETA: 10:07 - loss: 1.3835 - accuracy: 0.8552WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "196/285 [===================>..........] - ETA: 10:00 - loss: 1.3807 - accuracy: 0.8552WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "197/285 [===================>..........] - ETA: 9:53 - loss: 1.3741 - accuracy: 0.8559 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "198/285 [===================>..........] - ETA: 9:47 - loss: 1.3678 - accuracy: 0.8563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "199/285 [===================>..........] - ETA: 9:40 - loss: 1.3621 - accuracy: 0.8564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/285 [====================>.........] - ETA: 9:34 - loss: 1.3562 - accuracy: 0.8567WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "201/285 [====================>.........] - ETA: 9:27 - loss: 1.3503 - accuracy: 0.8571WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "202/285 [====================>.........] - ETA: 9:20 - loss: 1.3454 - accuracy: 0.8575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "203/285 [====================>.........] - ETA: 9:13 - loss: 1.3395 - accuracy: 0.8580WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "204/285 [====================>.........] - ETA: 9:06 - loss: 1.3337 - accuracy: 0.8582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "205/285 [====================>.........] - ETA: 9:00 - loss: 1.3275 - accuracy: 0.8589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "206/285 [====================>.........] - ETA: 8:53 - loss: 1.3224 - accuracy: 0.8589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "207/285 [====================>.........] - ETA: 8:46 - loss: 1.3177 - accuracy: 0.8589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "208/285 [====================>.........] - ETA: 8:39 - loss: 1.3122 - accuracy: 0.8592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "209/285 [=====================>........] - ETA: 8:32 - loss: 1.3094 - accuracy: 0.8588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "210/285 [=====================>........] - ETA: 8:26 - loss: 1.3039 - accuracy: 0.8593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "211/285 [=====================>........] - ETA: 8:19 - loss: 1.3000 - accuracy: 0.8591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "212/285 [=====================>........] - ETA: 8:12 - loss: 1.2962 - accuracy: 0.8592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "213/285 [=====================>........] - ETA: 8:05 - loss: 1.2908 - accuracy: 0.8595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "214/285 [=====================>........] - ETA: 7:58 - loss: 1.2854 - accuracy: 0.8602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "215/285 [=====================>........] - ETA: 7:52 - loss: 1.2804 - accuracy: 0.8604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "216/285 [=====================>........] - ETA: 7:45 - loss: 1.2766 - accuracy: 0.8605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "217/285 [=====================>........] - ETA: 7:38 - loss: 1.2719 - accuracy: 0.8605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "218/285 [=====================>........] - ETA: 7:31 - loss: 1.2667 - accuracy: 0.8609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "219/285 [======================>.......] - ETA: 7:25 - loss: 1.2622 - accuracy: 0.8610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "220/285 [======================>.......] - ETA: 7:18 - loss: 1.2577 - accuracy: 0.8613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "221/285 [======================>.......] - ETA: 7:11 - loss: 1.2573 - accuracy: 0.8612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "222/285 [======================>.......] - ETA: 7:04 - loss: 1.2521 - accuracy: 0.8619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "223/285 [======================>.......] - ETA: 6:58 - loss: 1.2480 - accuracy: 0.8619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "224/285 [======================>.......] - ETA: 6:51 - loss: 1.2439 - accuracy: 0.8620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "225/285 [======================>.......] - ETA: 6:44 - loss: 1.2400 - accuracy: 0.8620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "226/285 [======================>.......] - ETA: 6:38 - loss: 1.2361 - accuracy: 0.8617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "227/285 [======================>.......] - ETA: 6:31 - loss: 1.2320 - accuracy: 0.8617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "228/285 [=======================>......] - ETA: 6:24 - loss: 1.2279 - accuracy: 0.8618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "229/285 [=======================>......] - ETA: 6:17 - loss: 1.2233 - accuracy: 0.8623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "230/285 [=======================>......] - ETA: 6:11 - loss: 1.2189 - accuracy: 0.8624WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "231/285 [=======================>......] - ETA: 6:04 - loss: 1.2157 - accuracy: 0.8622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "232/285 [=======================>......] - ETA: 5:57 - loss: 1.2114 - accuracy: 0.8623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "233/285 [=======================>......] - ETA: 5:50 - loss: 1.2067 - accuracy: 0.8625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "234/285 [=======================>......] - ETA: 5:44 - loss: 1.2028 - accuracy: 0.8624WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "235/285 [=======================>......] - ETA: 5:37 - loss: 1.1980 - accuracy: 0.8628WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "236/285 [=======================>......] - ETA: 5:30 - loss: 1.2012 - accuracy: 0.8626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "237/285 [=======================>......] - ETA: 5:23 - loss: 1.1965 - accuracy: 0.8632WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "238/285 [========================>.....] - ETA: 5:17 - loss: 1.1922 - accuracy: 0.8635WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "239/285 [========================>.....] - ETA: 5:10 - loss: 1.1884 - accuracy: 0.8638WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "240/285 [========================>.....] - ETA: 5:03 - loss: 1.1848 - accuracy: 0.8641WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "241/285 [========================>.....] - ETA: 4:57 - loss: 1.1810 - accuracy: 0.8643WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "242/285 [========================>.....] - ETA: 4:50 - loss: 1.1765 - accuracy: 0.8649WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "243/285 [========================>.....] - ETA: 4:43 - loss: 1.1732 - accuracy: 0.8647WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "244/285 [========================>.....] - ETA: 4:36 - loss: 1.1689 - accuracy: 0.8650WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "245/285 [========================>.....] - ETA: 4:30 - loss: 1.1673 - accuracy: 0.8650WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "246/285 [========================>.....] - ETA: 4:23 - loss: 1.1637 - accuracy: 0.8652WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "247/285 [=========================>....] - ETA: 4:16 - loss: 1.1598 - accuracy: 0.8655WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "248/285 [=========================>....] - ETA: 4:09 - loss: 1.1557 - accuracy: 0.8659WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "249/285 [=========================>....] - ETA: 4:03 - loss: 1.1513 - accuracy: 0.8664WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "250/285 [=========================>....] - ETA: 3:56 - loss: 1.1472 - accuracy: 0.8668WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "251/285 [=========================>....] - ETA: 3:49 - loss: 1.1434 - accuracy: 0.8672WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "252/285 [=========================>....] - ETA: 3:42 - loss: 1.1393 - accuracy: 0.8675WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "253/285 [=========================>....] - ETA: 3:36 - loss: 1.1364 - accuracy: 0.8677WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "254/285 [=========================>....] - ETA: 3:29 - loss: 1.1323 - accuracy: 0.8681WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "255/285 [=========================>....] - ETA: 3:22 - loss: 1.1288 - accuracy: 0.8682WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "256/285 [=========================>....] - ETA: 3:15 - loss: 1.1255 - accuracy: 0.8680WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "257/285 [==========================>...] - ETA: 3:09 - loss: 1.1219 - accuracy: 0.8684WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "258/285 [==========================>...] - ETA: 3:02 - loss: 1.1256 - accuracy: 0.8687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "259/285 [==========================>...] - ETA: 2:55 - loss: 1.1252 - accuracy: 0.8687WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "260/285 [==========================>...] - ETA: 2:48 - loss: 1.1213 - accuracy: 0.8690WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "261/285 [==========================>...] - ETA: 2:42 - loss: 1.1187 - accuracy: 0.8691WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "262/285 [==========================>...] - ETA: 2:35 - loss: 1.1155 - accuracy: 0.8691WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "263/285 [==========================>...] - ETA: 2:28 - loss: 1.1120 - accuracy: 0.8695WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "264/285 [==========================>...] - ETA: 2:21 - loss: 1.1084 - accuracy: 0.8698WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "265/285 [==========================>...] - ETA: 2:15 - loss: 1.1046 - accuracy: 0.8701WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/285 [===========================>..] - ETA: 2:08 - loss: 1.1024 - accuracy: 0.8701WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "267/285 [===========================>..] - ETA: 2:01 - loss: 1.0992 - accuracy: 0.8702WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "268/285 [===========================>..] - ETA: 1:54 - loss: 1.0955 - accuracy: 0.8707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "269/285 [===========================>..] - ETA: 1:47 - loss: 1.0920 - accuracy: 0.8708WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "270/285 [===========================>..] - ETA: 1:41 - loss: 1.0886 - accuracy: 0.8708WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "271/285 [===========================>..] - ETA: 1:34 - loss: 1.0854 - accuracy: 0.8709WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "272/285 [===========================>..] - ETA: 1:27 - loss: 1.0821 - accuracy: 0.8712WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "273/285 [===========================>..] - ETA: 1:20 - loss: 1.0792 - accuracy: 0.8711WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "274/285 [===========================>..] - ETA: 1:14 - loss: 1.0757 - accuracy: 0.8713WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "275/285 [===========================>..] - ETA: 1:07 - loss: 1.0721 - accuracy: 0.8718WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "276/285 [============================>.] - ETA: 1:00 - loss: 1.0691 - accuracy: 0.8719WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "277/285 [============================>.] - ETA: 54s - loss: 1.0655 - accuracy: 0.8723 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "278/285 [============================>.] - ETA: 47s - loss: 1.0623 - accuracy: 0.8725WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "279/285 [============================>.] - ETA: 40s - loss: 1.0589 - accuracy: 0.8728WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "280/285 [============================>.] - ETA: 33s - loss: 1.0556 - accuracy: 0.8730WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "281/285 [============================>.] - ETA: 27s - loss: 1.0522 - accuracy: 0.8733WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "282/285 [============================>.] - ETA: 20s - loss: 1.0490 - accuracy: 0.8736WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "283/285 [============================>.] - ETA: 13s - loss: 1.0464 - accuracy: 0.8738WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "284/285 [============================>.] - ETA: 6s - loss: 1.0441 - accuracy: 0.8739 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.8739WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "285/285 [==============================] - 2086s 7s/step - loss: 1.0411 - accuracy: 0.8739 - val_loss: 0.6699 - val_accuracy: 0.6682\n",
      "ResNet50 training took: 34.78 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "resnet50_his = resnet50_model.fit(train_generator,\n",
    "                            validation_data = validation_generator,\n",
    "                            batch_size = 32,\n",
    "                            epochs = 150,\n",
    "                            callbacks = [checkpoint, early])\n",
    "t2 = time.time()\n",
    "print('ResNet50 training took: {:.2f} minutes.'.format((t2 - t1)/ 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.041055</td>\n",
       "      <td>0.873875</td>\n",
       "      <td>0.669865</td>\n",
       "      <td>0.668226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.041055  0.873875  0.669865      0.668226"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resnet = pd.DataFrame(resnet50_his.history)\n",
    "df_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResNet50 cho kết quả thấp tương tự như khi sử dụng dữ liệu nhỏ cho pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
